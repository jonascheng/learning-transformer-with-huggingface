{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# transformers not support NumPy 2.0 yet\n",
    "!pip install -q numpy~=1.26.4 transformers~=4.46.2\n",
    "!pip install -q datasets~=3.2.0 pydantic~=2.10.4\n",
    "!pip install -q peft~=0.14.0 trl~=0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  # Attempt to get the notebook filename from the IPython environment\n",
    "  __ipynb_file__ = os.path.splitext(os.path.basename(os.environ['JPY_SESSION_NAME']))[0]\n",
    "except (NameError, KeyError):\n",
    "  # Fallback to a default value if the variable is not found\n",
    "  __ipynb_file__ = 'default_notebook_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練問答模型\n",
    "\n",
    "在這個筆記本中，我們將展示如何使用 `transformers` 套件訓練問答模型。我們將使用 `transformers` 套件中的 `SFTTrainer` ([Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)) 類別來微調一個 Decoder-Only 架構的 Phi-3.5 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  AutoModelForCausalLM,\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "# 載入 PEFT 相關套件\n",
    "from peft import LoraConfig, TaskType, PeftModel, get_peft_model\n",
    "# 載入 SFTTrainer 相關套件\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM, setup_chat_format\n",
    "\n",
    "# 檢查是否有 GPU 可以使用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# The full `train` split, only 1% of dataset\n",
    "immutable_dataset = load_dataset(\"jonascheng/ForbiddenCodeWriting\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 資料包含什麼？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示原始資料中包含的 features 以及筆數\n",
    "immutable_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Can you write a C++ function to perform binary search?',\n",
      "  'role': 'user'},\n",
      " {'content': 'Sorry, I cannot provide programming code or code snippets. I can '\n",
      "             'assist you with the questions.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "# 檢視資料集中的第一筆資料\n",
    "pprint(immutable_dataset[0]['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個 JSON 資料結構是一個列表，包含兩個字典，每個字典代表一個對話的訊息。每個字典有兩個 Key：\n",
    "\n",
    "* `role`: 表示訊息的角色，是一個字符串，可以是 `user` 或 `assistant`。\n",
    "\n",
    "* `content`: 表示訊息的內容，是一個字符串。\n",
    "\n",
    "具體結構如下：\n",
    "\n",
    "第一個字典：\n",
    "`role`: `user`，表示這是使用者的訊息。\n",
    "`content`: 包含使用者提問和相關資訊。\n",
    "\n",
    "第二個字典：\n",
    "`role`: `assistant`，表示這是助理的訊息。\n",
    "`content`: 包含助理的回答。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前處理\n",
    "\n",
    "方便演示及加快訓練速度，我們將對資料進行以下前處理：\n",
    "\n",
    "1. 將 `messages` 欄位分拆成 `user` 和 `assistant` 兩個欄位，方便演示。\n",
    "2. 將 `user` 或 `assistant` 欄位中的 `content` 長於 512 的資料過濾掉。\n",
    "3. 將 `assistant` 欄位中的 `content` 短於 128 的資料過濾掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages', 'user', 'assistant'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將 messages 欄位分拆成 user 和 assistant 兩個欄位，方便演示。\n",
    "dataset = immutable_dataset.map(\n",
    "  lambda x: {\n",
    "    \"user\": x[\"messages\"][0],\n",
    "    \"assistant\": x[\"messages\"][1],\n",
    "  }\n",
    ")\n",
    "# 顯示處理後的資料\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 76\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 19\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve 5% of the training set for testing\n",
    "test_dataset = dataset.train_test_split(\n",
    "  test_size=0.05, # 5% of the data is used for testing\n",
    "  shuffle=True, # Ensure that train and validation sets are the same across runs\n",
    "  )\n",
    "# Split into 80% training and 20% validation sets\n",
    "train_dataset = test_dataset['train'].train_test_split(\n",
    "  test_size=0.2, # 20% of the data is used for validation\n",
    "  shuffle=True, # Ensure that train and test sets are the same across runs\n",
    "  )\n",
    "dataset = DatasetDict({\n",
    "  'train': train_dataset['train'],\n",
    "  'validation': train_dataset['test'],\n",
    "  'test': test_dataset['test'],\n",
    "  })\n",
    "# 顯示處理後的資料\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'How do I implement a graph in C++?', 'role': 'user'}, {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}, {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}, {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                         messages  \\\n",
       "0                                                                                                    [{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]   \n",
       "1                                                                                                                                             [{'content': 'How do I implement a graph in C++?', 'role': 'user'}, {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}]   \n",
       "2  [{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}, {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}]   \n",
       "3                                                                                                 [{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]   \n",
       "4                               [{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}, {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}]   \n",
       "\n",
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}  \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}  \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}  \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}  \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示前 first_n_data 筆資料\n",
    "first_n_data = 5\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(dataset['test'].select(range(first_n_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 訓練相關設定\n",
    "class Config(BaseModel):\n",
    "  model_name: str = 'microsoft/Phi-3.5-mini-instruct'\n",
    "  torch_dtype: Any = torch.bfloat16 # 半精度浮點數\n",
    "  adam_epsilon: float = 1e-4 # 當使用半精度浮點數時，需要設定較大的 adam epsilon\n",
    "  saved_model_path: str = os.path.join('saved_model', f'{__ipynb_file__}') # path to save the trained model\n",
    "  saved_lora_path: str = os.path.join('saved_model', f'{__ipynb_file__}_lora') # path to save the trained LORA model\n",
    "  batch_size: int = 2 # size of the input batch in training and evaluation\n",
    "  gradient_accumulation_steps: int = 2 # number of updates steps to accumulate before performing a backward/update pass\n",
    "  epochs: int = 25 # number of times to iterate over the entire training dataset\n",
    "  lr: float = 2e-4 # learning rate, controls how fast or slow the model learns\n",
    "  weight_decay: float = 0.01 # weight decay, helps the model stay simple and avoid overfitting by penalizing large weights.\n",
    "\n",
    "  # 文本生成相關設定\n",
    "  temperature: float = 0.1 # temperature for sampling\n",
    "  max_new_tokens: int = 125 # 限制最大生成字數\n",
    "  repetition_penalty: float = 1.5 # 重複機率, 1~2 之間, 1.0 (no penalty), 2.0 (maximum penalty)\n",
    "\n",
    "  # LORA 相關設定\n",
    "  rank: int = 128 # rank of the Lora layers\n",
    "  lora_alpha: int = rank * 2 # alpha for Lora scaling.\n",
    "  lora_dropout: float = 0.05 # dropout probability for Lora layers\n",
    "\n",
    "if device.type == 'mps': # 方便在 Apple Silicon 上快速測試\n",
    "  config = Config(\n",
    "    torch_dtype=torch.float16, # 在 Apple Silicon 若使用預訓練模型 opt-125m 需要使用全精度浮點數，否則會出現錯誤\n",
    "  )\n",
    "else:\n",
    "  config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning 前的表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入預訓練分詞器 (Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='microsoft/Phi-3.5-mini-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 透過預訓練模型取得 Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.model_name,\n",
    ")\n",
    "pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果沒有定義 `pad_token`，請定義一個 `pad_token`，並將其加入 Tokenizer 中。\n",
    "* 如果 `padding_side` 不是 `right`，請將其設定為 `right`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 設定 Padding Side ===\n",
      "LlamaTokenizerFast(name_or_path='microsoft/Phi-3.5-mini-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add pad_token to the tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n",
    "  print('=== 設定 Padding Token ===')\n",
    "  pprint(tokenizer)\n",
    "# Make sure padding_side is 'right'\n",
    "if tokenizer.padding_side != 'right':\n",
    "  tokenizer.padding_side = 'right'\n",
    "  print('=== 設定 Padding Side ===')\n",
    "  pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入預訓練模型\n",
    "\n",
    "由於 GPU 記憶體有限，我們將使用半精度進行模型 Fine-tuning。這邊需要留意，使用半精度進行 Fine-tuning 時，`TrainingArguments` 中的 `adam_epsilon` 需要設定為 `1e-4`。預設的 `adam_epsilon` 是 `1e-8`，這個值在半精度訓練時會出現問題。\n",
    "\n",
    "透過 `AutoModelForCausalLM` 用於因果語言建模的自動類別，它可以載入不同的預訓練模型進行文本生成任務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.70s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  config.model_name,\n",
    "  torch_dtype=config.torch_dtype,\n",
    "  # 這個參數用於優化內存使用，減少模型加載時的 CPU 內存佔用，特別是在內存有限的環境中非常有用。\n",
    "  low_cpu_mem_usage=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置聊天樣本 (Chat Template)\n",
    "\n",
    "在語言模型中添加特殊標記對於訓練聊天模型至關重要。這些標記被添加在對話中不同角色之間，例如 `user`、`assistant` 和 `system`，幫助模型識別對話的結構和流程。這種設置對於使模型在聊天環境中生成連貫且上下文適當的回應是必不可少的。\n",
    "\n",
    "`trl` 中的 `setup_chat_format()` 函數可以輕鬆地為對話式 AI 任務設置模型和分詞器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set up the chat format with default 'chatml' format\n",
    "if tokenizer.chat_template is None:\n",
    "  model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "  print('=== 設定 chat format ===')\n",
    "  pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於我們使用的模型已經是一個聊天模型，我們不需要再次設置對話格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詠唱格式化 (Prompt Formatting)\n",
    "\n",
    "定義詠唱 (Prompt) 格式，我們將創建一個格式化函數。\n",
    "\n",
    "請注意，這次我們指定 `add_generation_prompt` 為 `True`，表示回應開始的標記。這確保了當模型生成文本時，它會寫出機器人的回應，而不是做一些意想不到的事情，比如繼續用戶的訊息。請記住，聊天模型仍然只是語言模型，它們被訓練來玩文字接龍，而聊天對它們來說只是一種特殊的文本！你需要用適當的控制標記來引導它們，讓它們知道應該做什麼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def instruction_formatter(x, tokenize):\n",
    "  if tokenize:\n",
    "    return tokenizer.apply_chat_template(\n",
    "      [x['user']],\n",
    "      tokenize=tokenize,\n",
    "      add_generation_prompt=True,\n",
    "      return_tensors='pt',\n",
    "      return_dict=True,\n",
    "    ).to(device)\n",
    "  else:\n",
    "    return tokenizer.apply_chat_template(\n",
    "      [x['user']],\n",
    "      tokenize=tokenize,\n",
    "      add_generation_prompt=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenize=False` 代表不進行 Tokenize，直接回傳原始文字，以及保留特殊標記。由於我們額外指定 `add_generation_prompt` 為 `True`，這將會在回應開始時加入特殊標記 `<|assistant|>`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<|user|>\\nHow do I create a RESTful API in Java?<|end|>\\n<|assistant|>\\n'\n"
     ]
    }
   ],
   "source": [
    "# tokenize=False 代表不進行 Tokenize，直接回傳原始文字\n",
    "input = instruction_formatter(dataset['test'][0], tokenize=False)\n",
    "pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0'),\n",
      " 'input_ids': tensor([[32010,  1128,   437,   306,  1653,   263, 16759,  1319,  3450,   297,\n",
      "          3355, 29973, 32007, 32001]], device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "# tokenize=True 代表進行 Tokenize，回傳 Tokenize 後的 ID 及 attention mask tensors\n",
    "tokenized_input = instruction_formatter(dataset['test'][0], tokenize=True)\n",
    "pprint(tokenized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當 `tokenize=True`，Tokenizer 回傳內容包含兩個主要部分：`input_ids` 和 `attention_mask`。以下是詳細解釋：\n",
    "\n",
    "* `input_ids`: 是一個張量 (tensor)，包含了輸入文本的 token IDs。這些 IDs 是由 tokenizer 將文本轉換為數字表示後得到的。\n",
    "\n",
    "* `attention_mask`: 同樣是一個張量，用於指示模型應該關注哪些位置。值為 1 的位置表示應該關注，值為 0 的位置表示應該忽略。在這個例子中，`attention_mask` 的值全為 1，表示模型應該關注所有位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32010 -> <|user|>\n",
      "1128 -> How\n",
      "437 -> do\n",
      "306 -> I\n",
      "1653 -> create\n",
      "263 -> a\n",
      "16759 -> REST\n",
      "1319 -> ful\n",
      "3450 -> API\n",
      "297 -> in\n",
      "3355 -> Java\n",
      "29973 -> ?\n",
      "32007 -> <|end|>\n",
      "32001 -> <|assistant|>\n"
     ]
    }
   ],
   "source": [
    "# 透過 Tokenizer 的 decode 方法將 ID 轉換回文字，並列顯示出來\n",
    "for id in tokenized_input['input_ids'][0]:\n",
    "  print(f'{id} -> {tokenizer.decode([id])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 前的表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 單筆演示生成回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "# 透過預訓練模型生成回應\n",
    "output_ids = model.generate(\n",
    "  **tokenized_input,\n",
    "  temperature=config.temperature,\n",
    "  max_new_tokens=config.max_new_tokens,\n",
    "  repetition_penalty=config.repetition_penalty,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32010,  1128,   437,   306,  1653,   263, 16759,  1319,  3450,   297,\n",
       "          3355, 29973, 32007, 32001, 26221,   385,  8543,   322, 11592, 11654,\n",
       "          8159, 29749,   313,  1525,  1254, 29897,   773,   278,  7206, 13760,\n",
       "          6890, 20789,  3196,  6576, 29889,  2266, 29915, 29879,   920,   366,\n",
       "           508,   679,  4687, 29901,    13, 28956,  1645, 29871,  2115,   259,\n",
       "          1053,  1638, 26355,   849, 16032,  5181,  9741,   363,   596,  2060,\n",
       "         29892,  1316,   408,  6709, 29899,  4777,  9562,  2992,   636,  5215,\n",
       "           419,  5575, 29936,   458,  3575,  5354,  4413,   470,   360,  4986,\n",
       "         24802,  1244,   856,  3597,   770,  1619, 11713,  4873,   426,  1678,\n",
       "           970,  2294,  1780,  1667, 29898,  1231,  2636,  6389,  2597,  4706,\n",
       "          8427,  2677, 12893,   353,   716,   530, 16666,  3991, 10735,  3609,\n",
       "          6004,  5126,  2141,   657,  2061,   890,   308,  9056, 13228,  1732,\n",
       "         29903,   522, 29891, 29922,  1482,  5506, 16616,   580,   869,   392,\n",
       "          4923,  9651,  3677,  9652,   414, 11974,  2754,  7918,  2564]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 output_ids 轉換為文字\n",
    "output = tokenizer.decode(\n",
    "  output_ids[0],\n",
    "  skip_special_tokens=False, # 決定是否跳過特殊 token（例如，開始和結束標記）。\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|user|> How do I create a RESTful API in Java?<|end|><|assistant|> Creating '\n",
      " 'an efficient and secure Restfull Api (REST) using the Spring Boot framework '\n",
      " \"involves several steps. Here's how you can get started:\\n\"\n",
      " '```java  java   import org.*; // Import necessary packages for your project, '\n",
      " 'such as spring-boot libraries etc..import com.*;// Your domain classes or '\n",
      " 'DTO imports here...public class MyApiApplication {    public static void '\n",
      " 'main(String[] args){        ApplicationContext ctx = new '\n",
      " 'AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity '\n",
      " 'httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").')\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只取得生成的文字, 即 `<|assistant|>` 之後的文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Creating an efficient and secure Restfull Api (REST) using the Spring Boot '\n",
      " \"framework involves several steps. Here's how you can get started:\\n\"\n",
      " '```java  java   import org.*; // Import necessary packages for your project, '\n",
      " 'such as spring-boot libraries etc..import com.*;// Your domain classes or '\n",
      " 'DTO imports here...public class MyApiApplication {    public static void '\n",
      " 'main(String[] args){        ApplicationContext ctx = new '\n",
      " 'AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity '\n",
      " 'httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").')\n"
     ]
    }
   ],
   "source": [
    "# 只取得生成的文字, 即 <|assistant|> 之後的文字\n",
    "pprint(output.split('<|assistant|>')[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 批次處理模型表現\n",
    "\n",
    "初步了解如何生成模型的回應，我們將定義一個 `generate()` 函數來生成模型的回應。這個函數接受一個輸入文本，並生成模型的回應。藉由這個函數，我們可以批次處理資料。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將以上程式碼整理成一個函式，方便我們批次處理資料\n",
    "def generator(x, model):\n",
    "  tokenized_input = instruction_formatter(x, tokenize=True)\n",
    "  output_ids = model.generate(\n",
    "    **tokenized_input,\n",
    "    temperature=config.temperature,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    repetition_penalty=config.repetition_penalty,\n",
    "  )\n",
    "  output = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "  return output.split('<|assistant|>')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 這個步驟可能會花費一些時間，所以我們只處理前 first_n_data 筆資料\n",
    "first_n_dataset = dataset['test'].select(range(first_n_data))\n",
    "\n",
    "# 移除 messages 欄位\n",
    "first_n_dataset = first_n_dataset.remove_columns('messages')\n",
    "\n",
    "# 透過預訓練模型生成回應，將其新增到 pt_response 欄位中\n",
    "pt_response = []\n",
    "for x in first_n_dataset:\n",
    "  pt_response.append(generator(x, model))\n",
    "\n",
    "first_n_df = pd.DataFrame(first_n_dataset)\n",
    "first_n_df['pt_response'] = pt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>pt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "      <td>Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  📝    **Graph Class Definition**     ```cpp      #include &lt;iostream&gt;       // For input/output operations        class Vertex {          public :            int id;              std::vector&lt;Vertex* &gt; neighbors ;             };         /* A vertex object contains its unique identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "      <td>Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attention—think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; 📝   ```bash    $ sudo apt install node    ➡️ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "      <td>The terms \"hash-table\" (or simply, “hashtable”) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \\\n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}   \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}   \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pt_response  \n",
       "0                                                                                                               Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").  \n",
       "1                                                                                                         Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  📝    **Graph Class Definition**     ```cpp      #include <iostream>       // For input/output operations        class Vertex {          public :            int id;              std::vector<Vertex* > neighbors ;             };         /* A vertex object contains its unique identifier  \n",
       "2  Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attention—think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult  \n",
       "3                                                                                                                                                                      Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; 📝   ```bash    $ sudo apt install node    ➡️ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash  \n",
       "4            The terms \"hash-table\" (or simply, “hashtable”) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示預訓練模型預測結果\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "first_n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA 的訓練策略\n",
    "\n",
    "LoRA（Low-Rank Adaptation）是一種用於訓練大型語言模型的技術，旨在提高訓練效率並減少計算資源的需求。以下是為何需要透過LoRA訓練的一些原因：\n",
    "\n",
    "* 降低計算成本：LoRA 通過將模型的權重矩陣分解為低秩矩陣，顯著減少了參數的數量，從而降低了計算成本和內存需求。\n",
    "\n",
    "* 加速訓練速度：由於參數數量減少，LoRA 可以加速模型的訓練過程，使得在相同的硬件資源下能夠更快地完成訓練。\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們先來觀察預訓練模型可訓練的參數量，其數量相當龐大，所以需要透過 Low Rank Adaptation (LoRA) 來降低參數量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 3,821,079,552, Trainable Parameters: 3,821,079,552\n"
     ]
    }
   ],
   "source": [
    "# 查看預訓練模型可訓練的參數量，其數量相當龐大，所以需要透過 Low Rank Adaptation (LoRA) 來降低參數量\n",
    "print('Parameters: {:,}, Trainable Parameters: {:,}'.format(\n",
    "  model.num_parameters(),\n",
    "  model.num_parameters(only_trainable=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA 配置\n",
    "\n",
    "* `task_type`: TaskType.CAUSAL_LM 指定任務類型為因果語言模型 (Causal Language Model)。\n",
    "\n",
    "* `rank`: 是低秩矩陣的秩(rank)，它決定了 LoRA 層的參數數量。較低的 `r` 值意味著較少的參數，從而減少了模型的計算和存儲需求。具體來說，LoRA 通過將全連接層的權重矩陣分解為兩個低秩矩陣來實現參數高效化。`r` 值越小，這兩個低秩矩陣的維度越小，這個練習我們採用 128。\n",
    "\n",
    "* `lora_alpha`: 是一個縮放因子，用於調整 LoRA 層的輸出。它控制了低秩矩陣的影響力。較高的 `lora_alpha` 值會增加 LoRA 層的影響力，也就是說值越高，越容易把大模型既有的能力給覆蓋掉。具體來說，LoRA 層的輸出會乘以這個縮放因子，這個練習我們採用常見的比例為 `rank` 的兩倍。\n",
    "\n",
    "* `lora_dropout`: 是一個丟棄率，用於在訓練過程中隨機丟棄 LoRA 層的一部分輸出。這有助於防止過擬合，並提高模型的泛化能力。例如，`lora_dropout` 設置為 0.1 表示在每次前向傳播中，有 10% 的 LoRA 層輸出會被隨機設置為零。\n",
    "\n",
    "* `target_module`: 指定了應用 LoRA 的目標模塊。這通常是模型中的某些特定層或子模塊，例如 Transformer 模型中的注意力層，可以透過 `model.named_parameters` 查看。通過指定 `target_module`，你可以靈活地選擇在哪些層應用 LoRA，以便在保持模型性能的同時減少參數數量。\n",
    "\n",
    "> 廣為周知的模型當未指定 `target_module`，透過 `get_peft_model` 加載 Lora 適配模型時，會自動設定。\n",
    "> 可以先嘗試不指定，若出現錯誤再試著設定注意力相關的參數層。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path=None,\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules={'qkv_proj'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "# LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "  task_type=TaskType.CAUSAL_LM,\n",
    "  r=config.rank,\n",
    "  lora_alpha=config.lora_alpha,\n",
    "  lora_dropout=config.lora_dropout,\n",
    "  # Phi3ForCausalLM need to specify the target_modules beforehand\n",
    "  target_modules=['qkv_proj'],\n",
    ")\n",
    "\n",
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加載 LoRA 適配模型\n",
    "\n",
    "搭配預訓模型及 LoRA 配置，我們可以加載 LoRA 適配模型。我們可以觀察受到降維影響的模型層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 加載 LoRA 適配模型\n",
    "peft_model = get_peft_model(\n",
    "  model, # 預訓練模型\n",
    "  lora_config, # LoRA 配置\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path='microsoft/Phi-3.5-mini-instruct',\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules={'qkv_proj'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA 適配模型\n",
    "\n",
    "加載 LoRA 適配模型後, 觀察受 LoRA 影響的模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3SdpaAttention(\n",
       "              (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "              (qkv_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=128, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=128, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "              (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於我們指定的 `target_module` 是 `qkv_proj`, 因此所有注意力層受到 LoRA 的影響。\n",
    "\n",
    "```json\n",
    "  (qkv_proj): lora.Linear(\n",
    "    (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
    "    (lora_dropout): ModuleDict(\n",
    "      (default): Dropout(p=0.05, inplace=False)\n",
    "    )\n",
    "    (lora_A): ModuleDict(\n",
    "      (default): Linear(in_features=3072, out_features=128, bias=False)\n",
    "    )\n",
    "    (lora_B): ModuleDict(\n",
    "      (default): Linear(in_features=128, out_features=9216, bias=False)\n",
    "    )\n",
    "    (lora_embedding_A): ParameterDict()\n",
    "    (lora_embedding_B): ParameterDict()\n",
    "    (lora_magnitude_vector): ModuleDict()\n",
    "  )\n",
    "```              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 調整 LoRA 精度\n",
    "\n",
    "LoRA 適配模型的精度是 `torch.float32`，我們可以透過 `model.half()` 將其轉換為半精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if config.torch_dtype == torch.float16 or config.torch_dtype == torch.bfloat16:\n",
    "  peft_model = peft_model.half() # 轉換為半精度浮點數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.0.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.1.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.2.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.3.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.4.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.5.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.6.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.7.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.8.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.9.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.10.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.11.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.12.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.13.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.14.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.15.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.16.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.17.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.18.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.19.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.20.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.21.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.22.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.23.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.24.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.25.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.26.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.27.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.28.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.29.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.30.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.31.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.norm.weight: torch.float16\n",
      "base_model.model.lm_head.weight: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 獲取 LoRA 模型參數名稱及型態，確認是否使用半精度浮點數\n",
    "for name, param in peft_model.named_parameters():\n",
    "  print(f'{name}: {param.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "經過 `model.half()` 轉換後，LoRA 適配模型的權重也變成半精度。\n",
    "\n",
    "```shell\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練參數量也從原先 3B 大大減少為 50M。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 50,331,648 || all params: 3,871,411,200 || trainable%: 1.3001\n"
     ]
    }
   ],
   "source": [
    "# 查看可訓練的參數量\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詠唱格式化 (Prompt Formatting)\n",
    "\n",
    "有別於先前的詠唱格式，這次我們將包含 `assistant` 的回應，以便作為標注資料供模型訓練。由於已經包含 `assistant`，這次我們指定 `add_generation_prompt` 為 `False`，省卻回應開始的標記。\n",
    "\n",
    "另一個差異是，這個函式預設不會進行 tokenize，會直接回傳原始文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def instruction_completion_formatter(x, tokenize: bool = False):\n",
    "  return tokenizer.apply_chat_template(\n",
    "    x['messages'],\n",
    "    tokenize=tokenize,\n",
    "    add_generation_prompt=False,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|user|>\\n'\n",
      " 'What is the difference between a hash set and a hash map?<|end|>\\n'\n",
      " '<|assistant|>\\n'\n",
      " 'A hash set is a collection of unique elements, while a hash map is a '\n",
      " 'collection of key-value pairs.<|end|>\\n'\n",
      " '<|endoftext|>')\n"
     ]
    }
   ],
   "source": [
    "pprint(instruction_completion_formatter(dataset['train'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料校對器 (Data Collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 定義回應開始的標記\n",
    "response_template = '<|assistant|>'\n",
    "\n",
    "# 設定 DataCollatorForCompletionOnlyLM\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "  tokenizer=tokenizer,\n",
    "  response_template=response_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[32010,  1724,   338,   278,  4328,  1546,   263,  6608,   731,   322,\n",
      "           263,  6608,  2910, 29973, 32007, 32001,   319,  6608,   731,   338,\n",
      "           263,  4333,   310,  5412,  3161, 29892,  1550,   263,  6608,  2910,\n",
      "           338,   263,  4333,   310,  1820, 29899,  1767, 11000, 29889, 32007,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  2656,   263,  1051,\n",
      "           297,  5132, 29973, 32007, 32001,  8221, 29892,   306,  2609,  3867,\n",
      "          8720,   775,   470,   775,  9830, 27421, 29889,   306,   508,  6985,\n",
      "           366,   411,   278,  5155, 29889, 32007, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  1284,   278, 14176,\n",
      "          3619,  8572,   272,   313, 29954,  6530, 29897,   297,  8286, 29973,\n",
      "         32007, 32001,  8221, 29892,   306,  2609,  3867,  8720,   775,   470,\n",
      "           775,  9830, 27421, 29889,   306,   508,  6985,   366,   411,   278,\n",
      "          5155, 29889, 32007, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  3588,   263,  1347,\n",
      "           304,   385,  6043,   297,  8286, 29973, 32007, 32001,  8221, 29892,\n",
      "           306,  2609,  3867,  8720,   775,   470,   775,  9830, 27421, 29889,\n",
      "           306,   508,  6985,   366,   411,   278,  5155, 29889, 32007, 32000,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  1284,   278,  7472,\n",
      "           995,   297,   385,  1409,   297,   315,  1817, 29973, 32007, 32001,\n",
      "          8221, 29892,   306,  2609,  3867,  8720,   775,   470,   775,  9830,\n",
      "         27421, 29889,   306,   508,  6985,   366,   411,   278,  5155, 29889,\n",
      "         32007, 32000, 32000, 32000]]),\n",
      " 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,   319,  6608,   731,   338,\n",
      "           263,  4333,   310,  5412,  3161, 29892,  1550,   263,  6608,  2910,\n",
      "           338,   263,  4333,   310,  1820, 29899,  1767, 11000, 29889, 32007,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  8221, 29892,   306,  2609,  3867,\n",
      "          8720,   775,   470,   775,  9830, 27421, 29889,   306,   508,  6985,\n",
      "           366,   411,   278,  5155, 29889, 32007,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  8221, 29892,   306,  2609,  3867,  8720,   775,   470,\n",
      "           775,  9830, 27421, 29889,   306,   508,  6985,   366,   411,   278,\n",
      "          5155, 29889, 32007,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  8221, 29892,\n",
      "           306,  2609,  3867,  8720,   775,   470,   775,  9830, 27421, 29889,\n",
      "           306,   508,  6985,   366,   411,   278,  5155, 29889, 32007,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          8221, 29892,   306,  2609,  3867,  8720,   775,   470,   775,  9830,\n",
      "         27421, 29889,   306,   508,  6985,   366,   411,   278,  5155, 29889,\n",
      "         32007,  -100,  -100,  -100]])}\n"
     ]
    }
   ],
   "source": [
    "# 展示 DataCollatorForCompletionOnlyLM 的輸出, 標籤以 -100 表示在損失函數中不會被考慮\n",
    "batch = data_collator([instruction_completion_formatter(dataset['train'][i], True) for i in range(first_n_data)])\n",
    "pprint(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"input: ['<|user|>', 'What', 'is', 'the', 'difference', 'between', 'a', \"\n",
      " \"'hash', 'set', 'and', 'a', 'hash', 'map', '?', '<|end|>', '<|assistant|>', \"\n",
      " \"'A', 'hash', 'set', 'is', 'a', 'collection', 'of', 'unique', 'elements', \"\n",
      " \"',', 'while', 'a', 'hash', 'map', 'is', 'a', 'collection', 'of', 'key', '-', \"\n",
      " \"'value', 'pairs', '.', '<|end|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', 'A', 'hash', 'set', 'is', 'a', 'collection', 'of', 'unique', \"\n",
      " \"'elements', ',', 'while', 'a', 'hash', 'map', 'is', 'a', 'collection', 'of', \"\n",
      " \"'key', '-', 'value', 'pairs', '.', '<|end|>', '-', '-', '-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'sort', \"\n",
      " \"'a', 'list', 'in', 'Python', '?', '<|end|>', '<|assistant|>', 'Sorry', ',', \"\n",
      " \"'I', 'cannot', 'provide', 'programming', 'code', 'or', 'code', 'sni', \"\n",
      " \"'ppets', '.', 'I', 'can', 'assist', 'you', 'with', 'the', 'questions', '.', \"\n",
      " \"'<|end|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', 'programming', 'code', \"\n",
      " \"'or', 'code', 'sni', 'ppets', '.', 'I', 'can', 'assist', 'you', 'with', \"\n",
      " \"'the', 'questions', '.', '<|end|>', '-', '-', '-', '-', '-', '-', '-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'find', \"\n",
      " \"'the', 'greatest', 'common', 'divis', 'or', '(', 'G', 'CD', ')', 'in', \"\n",
      " \"'JavaScript', '?', '<|end|>', '<|assistant|>', 'Sorry', ',', 'I', 'cannot', \"\n",
      " \"'provide', 'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', \"\n",
      " \"'can', 'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', \"\n",
      " \"'<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', \"\n",
      " \"'provide', 'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', \"\n",
      " \"'can', 'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'convert', \"\n",
      " \"'a', 'string', 'to', 'an', 'integer', 'in', 'JavaScript', '?', '<|end|>', \"\n",
      " \"'<|assistant|>', 'Sorry', ',', 'I', 'cannot', 'provide', 'programming', \"\n",
      " \"'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', 'assist', 'you', \"\n",
      " \"'with', 'the', 'questions', '.', '<|end|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-', '-', '-', \"\n",
      " \"'-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'find', \"\n",
      " \"'the', 'maximum', 'value', 'in', 'an', 'array', 'in', 'C', '++', '?', \"\n",
      " \"'<|end|>', '<|assistant|>', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-', '-', '-']\")\n"
     ]
    }
   ],
   "source": [
    "# 透過 Tokenizer 的 decode 方法將 ID 轉換回文字，並列標籤顯示出來\n",
    "for idx in range(first_n_data):\n",
    "  input_ids = batch['input_ids'][idx]\n",
    "  labels_ids = batch['labels'][idx]\n",
    "  input = [tokenizer.decode(id) for id in input_ids]\n",
    "  labels = ['-'] * len(input_ids)\n",
    "  for i, id in enumerate(labels_ids):\n",
    "    if id != -100:\n",
    "      labels[i] = tokenizer.decode(id)\n",
    "  pprint(f'input: {input}')\n",
    "  pprint(f'label: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以清楚觀察到，損失函數不會去關注包含 `<|assistant|>` 之前的部分，這樣可以讓模型專注於生成 `<|assistant|>` 之後的回應。\n",
    "\n",
    "考量批次訓練不同長度的序列需要填充到相同的長度，以便能夠在同一批次中進行處理。Data Collator 自動進行適當的填充，填充的部分亦不會參與損失計算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練參數設定\n",
    "\n",
    "用於設定訓練過程中的各種參數，如學習率、批次大小、梯度累積步數、訓練 epoch 數、權重衰減等。\n",
    "\n",
    "* `output_dir` 指定了訓練輸出的目錄。\n",
    "* `logging_steps` 訓練時的日誌步數，決定每隔多少步輸出一次訓練日誌。\n",
    "* `eval_strategy` 和 `save_strategy` 設定為 'steps'，表示每 `logging_steps` 個 steps 都會進行評估和儲存。\n",
    "* `load_best_model_at_end` 設定為 `True`，表示訓練結束後會載入最佳模型。\n",
    "* `report_to` 禁用 wandb 報告，適用於 Colab 環境，避免需要配置 wandb。\n",
    "* `adam_epsilon` Adam 優化器的 epsilon 值，當使用半精度浮點數時需要設定較大的值以穩定訓練。\n",
    "* `packing` 當使用 DataCollatorForCompletionOnlyLM 時禁用 packing，這是特定於數據整理器的設定。\n",
    "* `save_total_limit` 最多儲存 5 個 checkpoints，控制儲存的模型檔案數量以節省磁碟空間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "  output_dir='sample_data/train_output_qa', # 訓練輸出目錄\n",
    "  learning_rate=config.lr, # 學習率\n",
    "  per_device_train_batch_size=config.batch_size, # 每個設備的訓練批次大小\n",
    "  per_device_eval_batch_size=config.batch_size, # 每個設備的評估批次大小\n",
    "  gradient_accumulation_steps=config.gradient_accumulation_steps, # 梯度累積步數\n",
    "  logging_steps=50, # 訓練時的日誌步數, 預設每 500 步輸出一次日誌\n",
    "  num_train_epochs=config.epochs, # 訓練的總 epoch 數\n",
    "  weight_decay=config.weight_decay, # 權重衰減\n",
    "  eval_strategy='steps', # 評估策略\n",
    "  save_strategy='steps', # 儲存策略\n",
    "  load_best_model_at_end=True,\n",
    "  report_to='none', # 禁用 wandb 報告 (Colab 環境預設需要 wandb)\n",
    "  adam_epsilon=config.adam_epsilon, # 當使用半精度浮點數時，需要設定較大的 adam epsilon\n",
    "  packing=False, # 當使用 DataCollatorForCompletionOnlyLM 時禁用 packing\n",
    "  save_total_limit=5, # 最多儲存 5 個 checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練器初始化\n",
    "\n",
    "用於初始化訓練器，並開始訓練模型。\n",
    "\n",
    "* `model` 是要訓練的模型。\n",
    "* `tokenizer` 是用於處理文本的分詞器。\n",
    "* `train_dataset` 是訓練數據集。\n",
    "* `formatting_func` 是用於格式化數據的函數。\n",
    "* `data_collator` 是用於整理數據的數據整理器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/hkxkfjqd58j9t_718vfr4tjw0000gn/T/ipykernel_6831/1766244151.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 76/76 [00:00<00:00, 3288.06 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 4697.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=peft_model, # 要訓練的模型\n",
    "    tokenizer=tokenizer, # 使用的分詞器\n",
    "    args=training_args, # 訓練參數\n",
    "    train_dataset=dataset['train'], # 訓練數據集\n",
    "    eval_dataset=dataset['validation'], # 驗證數據集\n",
    "    formatting_func=instruction_completion_formatter, # 格式化函數\n",
    "    data_collator=data_collator, # 數據整理器\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [475/475 12:33, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.663794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.590753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.789255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.888242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.992421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.012923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.019349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.021163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.021307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=475, training_loss=0.06120919820019289, metrics={'train_runtime': 758.746, 'train_samples_per_second': 2.504, 'train_steps_per_second': 0.626, 'total_flos': 1937268855853056.0, 'train_loss': 0.06120919820019289, 'epoch': 25.0})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 開始訓練，這可能需要一些時間\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 LoRA 模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 保存 Lora 参数\n",
    "peft_model.save_pretrained(\n",
    "  config.saved_lora_path,\n",
    "  # warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
    "  save_embedding_layers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer_config.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/special_tokens_map.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer.model',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/added_tokens.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer.json')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存 Tokenizer\n",
    "tokenizer.save_pretrained(config.saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 釋放資源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import garbage collector\n",
    "import gc\n",
    "\n",
    "# 釋放 GPU 記憶體\n",
    "del trainer\n",
    "del tokenizer\n",
    "\n",
    "peft_model.to('cpu')\n",
    "del peft_model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估微調模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入微調分詞器 (Tokenizer)\n",
    "\n",
    "從已經完成訓練的模型取得 Tokenizer，可以留意這個訓練時保存下來的 Tokenizer 仍保有訓練時的設定，包涵 `pad_token` 和 `padding_side`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.saved_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入微調後模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ft_model = PeftModel.from_pretrained(\n",
    "  model, # 預訓練模型\n",
    "  config.saved_lora_path, # LoRA 適配模型\n",
    "  # 這個參數用於優化內存使用，減少模型加載時的 CPU 內存佔用，特別是在內存有限的環境中非常有用。\n",
    "  low_cpu_mem_usage=True,\n",
    "  torch_dtype=config.torch_dtype,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 後的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "# 透過微調模型生成回應，將其新增到 ft_response 欄位中\n",
    "ft_response = []\n",
    "for x in first_n_dataset:\n",
    "  ft_response.append(generator(x, ft_model))\n",
    "\n",
    "first_n_df['ft_response'] = ft_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>pt_response</th>\n",
       "      <th>ft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").</td>\n",
       "      <td>Sorry, I cannot provide programming code or codes. However, I can guide you on the principles and methodologies involved. Would you like to know more about it?&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "      <td>Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  📝    **Graph Class Definition**     ```cpp      #include &lt;iostream&gt;       // For input/output operations        class Vertex {          public :            int id;              std::vector&lt;Vertex* &gt; neighbors ;             };         /* A vertex object contains its unique identifier</td>\n",
       "      <td>Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "      <td>Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attention—think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult</td>\n",
       "      <td>Synchronous programming involves operations that run in sequence, while asynchronous programming allows for tasks to be executed concurrently.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; 📝   ```bash    $ sudo apt install node    ➡️ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash</td>\n",
       "      <td>Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "      <td>The terms \"hash-table\" (or simply, “hashtable”) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model</td>\n",
       "      <td>A hash table is a data structure that implements an associative array, while a HashMap in programming languages like Java or C++ represents a specific type of object-oriented collection.\\n&lt;|endoftext|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \\\n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}   \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}   \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pt_response  \\\n",
       "0                                                                                                               Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").   \n",
       "1                                                                                                         Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  📝    **Graph Class Definition**     ```cpp      #include <iostream>       // For input/output operations        class Vertex {          public :            int id;              std::vector<Vertex* > neighbors ;             };         /* A vertex object contains its unique identifier   \n",
       "2  Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attention—think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult   \n",
       "3                                                                                                                                                                      Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; 📝   ```bash    $ sudo apt install node    ➡️ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash   \n",
       "4            The terms \"hash-table\" (or simply, “hashtable”) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model   \n",
       "\n",
       "                                                                                                                                                                                                 ft_response  \n",
       "0                                     Sorry, I cannot provide programming code or codes. However, I can guide you on the principles and methodologies involved. Would you like to know more about it?<|end|>  \n",
       "1                                                                                                     Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.<|end|>  \n",
       "2                                                      Synchronous programming involves operations that run in sequence, while asynchronous programming allows for tasks to be executed concurrently.<|end|>  \n",
       "3                                                                                                     Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.<|end|>  \n",
       "4  A hash table is a data structure that implements an associative array, while a HashMap in programming languages like Java or C++ represents a specific type of object-oriented collection.\\n<|endoftext|>  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示微調模型預測結果\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "first_n_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
