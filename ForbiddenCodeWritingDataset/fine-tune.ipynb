{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# transformers not support NumPy 2.0 yet\n",
    "!pip install -q numpy~=1.26.4 transformers~=4.46.2\n",
    "!pip install -q datasets~=3.2.0 pydantic~=2.10.4\n",
    "!pip install -q peft~=0.14.0 trl~=0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  # Attempt to get the notebook filename from the IPython environment\n",
    "  __ipynb_file__ = os.path.splitext(os.path.basename(os.environ['JPY_SESSION_NAME']))[0]\n",
    "except (NameError, KeyError):\n",
    "  # Fallback to a default value if the variable is not found\n",
    "  __ipynb_file__ = 'default_notebook_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¨“ç·´å•ç­”æ¨¡å‹\n",
    "\n",
    "åœ¨é€™å€‹ç­†è¨˜æœ¬ä¸­ï¼Œæˆ‘å€‘å°‡å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `transformers` å¥—ä»¶è¨“ç·´å•ç­”æ¨¡å‹ã€‚æˆ‘å€‘å°‡ä½¿ç”¨ `transformers` å¥—ä»¶ä¸­çš„ `SFTTrainer` ([Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)) é¡åˆ¥ä¾†å¾®èª¿ä¸€å€‹ Decoder-Only æ¶æ§‹çš„ Phi-3.5 æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  AutoModelForCausalLM,\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "# è¼‰å…¥ PEFT ç›¸é—œå¥—ä»¶\n",
    "from peft import LoraConfig, TaskType, PeftModel, get_peft_model\n",
    "# è¼‰å…¥ SFTTrainer ç›¸é—œå¥—ä»¶\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM, setup_chat_format\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰ GPU å¯ä»¥ä½¿ç”¨\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‹è¼‰è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# The full `train` split, only 1% of dataset\n",
    "immutable_dataset = load_dataset(\"jonascheng/ForbiddenCodeWriting\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### è³‡æ–™åŒ…å«ä»€éº¼ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é¡¯ç¤ºåŸå§‹è³‡æ–™ä¸­åŒ…å«çš„ features ä»¥åŠç­†æ•¸\n",
    "immutable_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Can you write a C++ function to perform binary search?',\n",
      "  'role': 'user'},\n",
      " {'content': 'Sorry, I cannot provide programming code or code snippets. I can '\n",
      "             'assist you with the questions.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "# æª¢è¦–è³‡æ–™é›†ä¸­çš„ç¬¬ä¸€ç­†è³‡æ–™\n",
    "pprint(immutable_dataset[0]['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€™å€‹ JSON è³‡æ–™çµæ§‹æ˜¯ä¸€å€‹åˆ—è¡¨ï¼ŒåŒ…å«å…©å€‹å­—å…¸ï¼Œæ¯å€‹å­—å…¸ä»£è¡¨ä¸€å€‹å°è©±çš„è¨Šæ¯ã€‚æ¯å€‹å­—å…¸æœ‰å…©å€‹ Keyï¼š\n",
    "\n",
    "* `role`: è¡¨ç¤ºè¨Šæ¯çš„è§’è‰²ï¼Œæ˜¯ä¸€å€‹å­—ç¬¦ä¸²ï¼Œå¯ä»¥æ˜¯ `user` æˆ– `assistant`ã€‚\n",
    "\n",
    "* `content`: è¡¨ç¤ºè¨Šæ¯çš„å…§å®¹ï¼Œæ˜¯ä¸€å€‹å­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "å…·é«”çµæ§‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "ç¬¬ä¸€å€‹å­—å…¸ï¼š\n",
    "`role`: `user`ï¼Œè¡¨ç¤ºé€™æ˜¯ä½¿ç”¨è€…çš„è¨Šæ¯ã€‚\n",
    "`content`: åŒ…å«ä½¿ç”¨è€…æå•å’Œç›¸é—œè³‡è¨Šã€‚\n",
    "\n",
    "ç¬¬äºŒå€‹å­—å…¸ï¼š\n",
    "`role`: `assistant`ï¼Œè¡¨ç¤ºé€™æ˜¯åŠ©ç†çš„è¨Šæ¯ã€‚\n",
    "`content`: åŒ…å«åŠ©ç†çš„å›ç­”ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è³‡æ–™å‰è™•ç†\n",
    "\n",
    "æ–¹ä¾¿æ¼”ç¤ºåŠåŠ å¿«è¨“ç·´é€Ÿåº¦ï¼Œæˆ‘å€‘å°‡å°è³‡æ–™é€²è¡Œä»¥ä¸‹å‰è™•ç†ï¼š\n",
    "\n",
    "1. å°‡ `messages` æ¬„ä½åˆ†æ‹†æˆ `user` å’Œ `assistant` å…©å€‹æ¬„ä½ï¼Œæ–¹ä¾¿æ¼”ç¤ºã€‚\n",
    "2. å°‡ `user` æˆ– `assistant` æ¬„ä½ä¸­çš„ `content` é•·æ–¼ 512 çš„è³‡æ–™éæ¿¾æ‰ã€‚\n",
    "3. å°‡ `assistant` æ¬„ä½ä¸­çš„ `content` çŸ­æ–¼ 128 çš„è³‡æ–™éæ¿¾æ‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages', 'user', 'assistant'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°‡ messages æ¬„ä½åˆ†æ‹†æˆ user å’Œ assistant å…©å€‹æ¬„ä½ï¼Œæ–¹ä¾¿æ¼”ç¤ºã€‚\n",
    "dataset = immutable_dataset.map(\n",
    "  lambda x: {\n",
    "    \"user\": x[\"messages\"][0],\n",
    "    \"assistant\": x[\"messages\"][1],\n",
    "  }\n",
    ")\n",
    "# é¡¯ç¤ºè™•ç†å¾Œçš„è³‡æ–™\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 76\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 19\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages', 'user', 'assistant'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve 5% of the training set for testing\n",
    "test_dataset = dataset.train_test_split(\n",
    "  test_size=0.05, # 5% of the data is used for testing\n",
    "  shuffle=True, # Ensure that train and validation sets are the same across runs\n",
    "  )\n",
    "# Split into 80% training and 20% validation sets\n",
    "train_dataset = test_dataset['train'].train_test_split(\n",
    "  test_size=0.2, # 20% of the data is used for validation\n",
    "  shuffle=True, # Ensure that train and test sets are the same across runs\n",
    "  )\n",
    "dataset = DatasetDict({\n",
    "  'train': train_dataset['train'],\n",
    "  'validation': train_dataset['test'],\n",
    "  'test': test_dataset['test'],\n",
    "  })\n",
    "# é¡¯ç¤ºè™•ç†å¾Œçš„è³‡æ–™\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'How do I implement a graph in C++?', 'role': 'user'}, {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}, {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}, {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}]</td>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                         messages  \\\n",
       "0                                                                                                    [{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]   \n",
       "1                                                                                                                                             [{'content': 'How do I implement a graph in C++?', 'role': 'user'}, {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}]   \n",
       "2  [{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}, {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}]   \n",
       "3                                                                                                 [{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}, {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}]   \n",
       "4                               [{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}, {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}]   \n",
       "\n",
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}  \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}  \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}  \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}  \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é¡¯ç¤ºå‰ first_n_data ç­†è³‡æ–™\n",
    "first_n_data = 5\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(dataset['test'].select(range(first_n_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¨“ç·´åƒæ•¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¨“ç·´è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# è¨“ç·´ç›¸é—œè¨­å®š\n",
    "class Config(BaseModel):\n",
    "  model_name: str = 'microsoft/Phi-3.5-mini-instruct'\n",
    "  torch_dtype: Any = torch.bfloat16 # åŠç²¾åº¦æµ®é»æ•¸\n",
    "  adam_epsilon: float = 1e-4 # ç•¶ä½¿ç”¨åŠç²¾åº¦æµ®é»æ•¸æ™‚ï¼Œéœ€è¦è¨­å®šè¼ƒå¤§çš„ adam epsilon\n",
    "  saved_model_path: str = os.path.join('saved_model', f'{__ipynb_file__}') # path to save the trained model\n",
    "  saved_lora_path: str = os.path.join('saved_model', f'{__ipynb_file__}_lora') # path to save the trained LORA model\n",
    "  batch_size: int = 2 # size of the input batch in training and evaluation\n",
    "  gradient_accumulation_steps: int = 2 # number of updates steps to accumulate before performing a backward/update pass\n",
    "  epochs: int = 25 # number of times to iterate over the entire training dataset\n",
    "  lr: float = 2e-4 # learning rate, controls how fast or slow the model learns\n",
    "  weight_decay: float = 0.01 # weight decay, helps the model stay simple and avoid overfitting by penalizing large weights.\n",
    "\n",
    "  # æ–‡æœ¬ç”Ÿæˆç›¸é—œè¨­å®š\n",
    "  temperature: float = 0.1 # temperature for sampling\n",
    "  max_new_tokens: int = 125 # é™åˆ¶æœ€å¤§ç”Ÿæˆå­—æ•¸\n",
    "  repetition_penalty: float = 1.5 # é‡è¤‡æ©Ÿç‡, 1~2 ä¹‹é–“, 1.0 (no penalty), 2.0 (maximum penalty)\n",
    "\n",
    "  # LORA ç›¸é—œè¨­å®š\n",
    "  rank: int = 128 # rank of the Lora layers\n",
    "  lora_alpha: int = rank * 2 # alpha for Lora scaling.\n",
    "  lora_dropout: float = 0.05 # dropout probability for Lora layers\n",
    "\n",
    "if device.type == 'mps': # æ–¹ä¾¿åœ¨ Apple Silicon ä¸Šå¿«é€Ÿæ¸¬è©¦\n",
    "  config = Config(\n",
    "    torch_dtype=torch.float16, # åœ¨ Apple Silicon è‹¥ä½¿ç”¨é è¨“ç·´æ¨¡å‹ opt-125m éœ€è¦ä½¿ç”¨å…¨ç²¾åº¦æµ®é»æ•¸ï¼Œå¦å‰‡æœƒå‡ºç¾éŒ¯èª¤\n",
    "  )\n",
    "else:\n",
    "  config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning å‰çš„è¡¨ç¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼‰å…¥é è¨“ç·´åˆ†è©å™¨ (Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='microsoft/Phi-3.5-mini-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# é€éé è¨“ç·´æ¨¡å‹å–å¾— Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.model_name,\n",
    ")\n",
    "pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* å¦‚æœæ²’æœ‰å®šç¾© `pad_token`ï¼Œè«‹å®šç¾©ä¸€å€‹ `pad_token`ï¼Œä¸¦å°‡å…¶åŠ å…¥ Tokenizer ä¸­ã€‚\n",
    "* å¦‚æœ `padding_side` ä¸æ˜¯ `right`ï¼Œè«‹å°‡å…¶è¨­å®šç‚º `right`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== è¨­å®š Padding Side ===\n",
      "LlamaTokenizerFast(name_or_path='microsoft/Phi-3.5-mini-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add pad_token to the tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n",
    "  print('=== è¨­å®š Padding Token ===')\n",
    "  pprint(tokenizer)\n",
    "# Make sure padding_side is 'right'\n",
    "if tokenizer.padding_side != 'right':\n",
    "  tokenizer.padding_side = 'right'\n",
    "  print('=== è¨­å®š Padding Side ===')\n",
    "  pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼‰å…¥é è¨“ç·´æ¨¡å‹\n",
    "\n",
    "ç”±æ–¼ GPU è¨˜æ†¶é«”æœ‰é™ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨åŠç²¾åº¦é€²è¡Œæ¨¡å‹ Fine-tuningã€‚é€™é‚Šéœ€è¦ç•™æ„ï¼Œä½¿ç”¨åŠç²¾åº¦é€²è¡Œ Fine-tuning æ™‚ï¼Œ`TrainingArguments` ä¸­çš„ `adam_epsilon` éœ€è¦è¨­å®šç‚º `1e-4`ã€‚é è¨­çš„ `adam_epsilon` æ˜¯ `1e-8`ï¼Œé€™å€‹å€¼åœ¨åŠç²¾åº¦è¨“ç·´æ™‚æœƒå‡ºç¾å•é¡Œã€‚\n",
    "\n",
    "é€é `AutoModelForCausalLM` ç”¨æ–¼å› æœèªè¨€å»ºæ¨¡çš„è‡ªå‹•é¡åˆ¥ï¼Œå®ƒå¯ä»¥è¼‰å…¥ä¸åŒçš„é è¨“ç·´æ¨¡å‹é€²è¡Œæ–‡æœ¬ç”Ÿæˆä»»å‹™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.70s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  config.model_name,\n",
    "  torch_dtype=config.torch_dtype,\n",
    "  # é€™å€‹åƒæ•¸ç”¨æ–¼å„ªåŒ–å…§å­˜ä½¿ç”¨ï¼Œæ¸›å°‘æ¨¡å‹åŠ è¼‰æ™‚çš„ CPU å…§å­˜ä½”ç”¨ï¼Œç‰¹åˆ¥æ˜¯åœ¨å…§å­˜æœ‰é™çš„ç’°å¢ƒä¸­éå¸¸æœ‰ç”¨ã€‚\n",
    "  low_cpu_mem_usage=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é…ç½®èŠå¤©æ¨£æœ¬ (Chat Template)\n",
    "\n",
    "åœ¨èªè¨€æ¨¡å‹ä¸­æ·»åŠ ç‰¹æ®Šæ¨™è¨˜å°æ–¼è¨“ç·´èŠå¤©æ¨¡å‹è‡³é—œé‡è¦ã€‚é€™äº›æ¨™è¨˜è¢«æ·»åŠ åœ¨å°è©±ä¸­ä¸åŒè§’è‰²ä¹‹é–“ï¼Œä¾‹å¦‚ `user`ã€`assistant` å’Œ `system`ï¼Œå¹«åŠ©æ¨¡å‹è­˜åˆ¥å°è©±çš„çµæ§‹å’Œæµç¨‹ã€‚é€™ç¨®è¨­ç½®å°æ–¼ä½¿æ¨¡å‹åœ¨èŠå¤©ç’°å¢ƒä¸­ç”Ÿæˆé€£è²«ä¸”ä¸Šä¸‹æ–‡é©ç•¶çš„å›æ‡‰æ˜¯å¿…ä¸å¯å°‘çš„ã€‚\n",
    "\n",
    "`trl` ä¸­çš„ `setup_chat_format()` å‡½æ•¸å¯ä»¥è¼•é¬†åœ°ç‚ºå°è©±å¼ AI ä»»å‹™è¨­ç½®æ¨¡å‹å’Œåˆ†è©å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set up the chat format with default 'chatml' format\n",
    "if tokenizer.chat_template is None:\n",
    "  model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "  print('=== è¨­å®š chat format ===')\n",
    "  pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”±æ–¼æˆ‘å€‘ä½¿ç”¨çš„æ¨¡å‹å·²ç¶“æ˜¯ä¸€å€‹èŠå¤©æ¨¡å‹ï¼Œæˆ‘å€‘ä¸éœ€è¦å†æ¬¡è¨­ç½®å°è©±æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è© å”±æ ¼å¼åŒ– (Prompt Formatting)\n",
    "\n",
    "å®šç¾©è© å”± (Prompt) æ ¼å¼ï¼Œæˆ‘å€‘å°‡å‰µå»ºä¸€å€‹æ ¼å¼åŒ–å‡½æ•¸ã€‚\n",
    "\n",
    "è«‹æ³¨æ„ï¼Œé€™æ¬¡æˆ‘å€‘æŒ‡å®š `add_generation_prompt` ç‚º `True`ï¼Œè¡¨ç¤ºå›æ‡‰é–‹å§‹çš„æ¨™è¨˜ã€‚é€™ç¢ºä¿äº†ç•¶æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ™‚ï¼Œå®ƒæœƒå¯«å‡ºæ©Ÿå™¨äººçš„å›æ‡‰ï¼Œè€Œä¸æ˜¯åšä¸€äº›æ„æƒ³ä¸åˆ°çš„äº‹æƒ…ï¼Œæ¯”å¦‚ç¹¼çºŒç”¨æˆ¶çš„è¨Šæ¯ã€‚è«‹è¨˜ä½ï¼ŒèŠå¤©æ¨¡å‹ä»ç„¶åªæ˜¯èªè¨€æ¨¡å‹ï¼Œå®ƒå€‘è¢«è¨“ç·´ä¾†ç©æ–‡å­—æ¥é¾ï¼Œè€ŒèŠå¤©å°å®ƒå€‘ä¾†èªªåªæ˜¯ä¸€ç¨®ç‰¹æ®Šçš„æ–‡æœ¬ï¼ä½ éœ€è¦ç”¨é©ç•¶çš„æ§åˆ¶æ¨™è¨˜ä¾†å¼•å°å®ƒå€‘ï¼Œè®“å®ƒå€‘çŸ¥é“æ‡‰è©²åšä»€éº¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def instruction_formatter(x, tokenize):\n",
    "  if tokenize:\n",
    "    return tokenizer.apply_chat_template(\n",
    "      [x['user']],\n",
    "      tokenize=tokenize,\n",
    "      add_generation_prompt=True,\n",
    "      return_tensors='pt',\n",
    "      return_dict=True,\n",
    "    ).to(device)\n",
    "  else:\n",
    "    return tokenizer.apply_chat_template(\n",
    "      [x['user']],\n",
    "      tokenize=tokenize,\n",
    "      add_generation_prompt=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenize=False` ä»£è¡¨ä¸é€²è¡Œ Tokenizeï¼Œç›´æ¥å›å‚³åŸå§‹æ–‡å­—ï¼Œä»¥åŠä¿ç•™ç‰¹æ®Šæ¨™è¨˜ã€‚ç”±æ–¼æˆ‘å€‘é¡å¤–æŒ‡å®š `add_generation_prompt` ç‚º `True`ï¼Œé€™å°‡æœƒåœ¨å›æ‡‰é–‹å§‹æ™‚åŠ å…¥ç‰¹æ®Šæ¨™è¨˜ `<|assistant|>`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<|user|>\\nHow do I create a RESTful API in Java?<|end|>\\n<|assistant|>\\n'\n"
     ]
    }
   ],
   "source": [
    "# tokenize=False ä»£è¡¨ä¸é€²è¡Œ Tokenizeï¼Œç›´æ¥å›å‚³åŸå§‹æ–‡å­—\n",
    "input = instruction_formatter(dataset['test'][0], tokenize=False)\n",
    "pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0'),\n",
      " 'input_ids': tensor([[32010,  1128,   437,   306,  1653,   263, 16759,  1319,  3450,   297,\n",
      "          3355, 29973, 32007, 32001]], device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "# tokenize=True ä»£è¡¨é€²è¡Œ Tokenizeï¼Œå›å‚³ Tokenize å¾Œçš„ ID åŠ attention mask tensors\n",
    "tokenized_input = instruction_formatter(dataset['test'][0], tokenize=True)\n",
    "pprint(tokenized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç•¶ `tokenize=True`ï¼ŒTokenizer å›å‚³å…§å®¹åŒ…å«å…©å€‹ä¸»è¦éƒ¨åˆ†ï¼š`input_ids` å’Œ `attention_mask`ã€‚ä»¥ä¸‹æ˜¯è©³ç´°è§£é‡‹ï¼š\n",
    "\n",
    "* `input_ids`: æ˜¯ä¸€å€‹å¼µé‡ (tensor)ï¼ŒåŒ…å«äº†è¼¸å…¥æ–‡æœ¬çš„ token IDsã€‚é€™äº› IDs æ˜¯ç”± tokenizer å°‡æ–‡æœ¬è½‰æ›ç‚ºæ•¸å­—è¡¨ç¤ºå¾Œå¾—åˆ°çš„ã€‚\n",
    "\n",
    "* `attention_mask`: åŒæ¨£æ˜¯ä¸€å€‹å¼µé‡ï¼Œç”¨æ–¼æŒ‡ç¤ºæ¨¡å‹æ‡‰è©²é—œæ³¨å“ªäº›ä½ç½®ã€‚å€¼ç‚º 1 çš„ä½ç½®è¡¨ç¤ºæ‡‰è©²é—œæ³¨ï¼Œå€¼ç‚º 0 çš„ä½ç½®è¡¨ç¤ºæ‡‰è©²å¿½ç•¥ã€‚åœ¨é€™å€‹ä¾‹å­ä¸­ï¼Œ`attention_mask` çš„å€¼å…¨ç‚º 1ï¼Œè¡¨ç¤ºæ¨¡å‹æ‡‰è©²é—œæ³¨æ‰€æœ‰ä½ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32010 -> <|user|>\n",
      "1128 -> How\n",
      "437 -> do\n",
      "306 -> I\n",
      "1653 -> create\n",
      "263 -> a\n",
      "16759 -> REST\n",
      "1319 -> ful\n",
      "3450 -> API\n",
      "297 -> in\n",
      "3355 -> Java\n",
      "29973 -> ?\n",
      "32007 -> <|end|>\n",
      "32001 -> <|assistant|>\n"
     ]
    }
   ],
   "source": [
    "# é€é Tokenizer çš„ decode æ–¹æ³•å°‡ ID è½‰æ›å›æ–‡å­—ï¼Œä¸¦åˆ—é¡¯ç¤ºå‡ºä¾†\n",
    "for id in tokenized_input['input_ids'][0]:\n",
    "  print(f'{id} -> {tokenizer.decode([id])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning å‰çš„è¡¨ç¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å–®ç­†æ¼”ç¤ºç”Ÿæˆå›æ‡‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "# é€éé è¨“ç·´æ¨¡å‹ç”Ÿæˆå›æ‡‰\n",
    "output_ids = model.generate(\n",
    "  **tokenized_input,\n",
    "  temperature=config.temperature,\n",
    "  max_new_tokens=config.max_new_tokens,\n",
    "  repetition_penalty=config.repetition_penalty,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32010,  1128,   437,   306,  1653,   263, 16759,  1319,  3450,   297,\n",
       "          3355, 29973, 32007, 32001, 26221,   385,  8543,   322, 11592, 11654,\n",
       "          8159, 29749,   313,  1525,  1254, 29897,   773,   278,  7206, 13760,\n",
       "          6890, 20789,  3196,  6576, 29889,  2266, 29915, 29879,   920,   366,\n",
       "           508,   679,  4687, 29901,    13, 28956,  1645, 29871,  2115,   259,\n",
       "          1053,  1638, 26355,   849, 16032,  5181,  9741,   363,   596,  2060,\n",
       "         29892,  1316,   408,  6709, 29899,  4777,  9562,  2992,   636,  5215,\n",
       "           419,  5575, 29936,   458,  3575,  5354,  4413,   470,   360,  4986,\n",
       "         24802,  1244,   856,  3597,   770,  1619, 11713,  4873,   426,  1678,\n",
       "           970,  2294,  1780,  1667, 29898,  1231,  2636,  6389,  2597,  4706,\n",
       "          8427,  2677, 12893,   353,   716,   530, 16666,  3991, 10735,  3609,\n",
       "          6004,  5126,  2141,   657,  2061,   890,   308,  9056, 13228,  1732,\n",
       "         29903,   522, 29891, 29922,  1482,  5506, 16616,   580,   869,   392,\n",
       "          4923,  9651,  3677,  9652,   414, 11974,  2754,  7918,  2564]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ output_ids è½‰æ›ç‚ºæ–‡å­—\n",
    "output = tokenizer.decode(\n",
    "  output_ids[0],\n",
    "  skip_special_tokens=False, # æ±ºå®šæ˜¯å¦è·³éç‰¹æ®Š tokenï¼ˆä¾‹å¦‚ï¼Œé–‹å§‹å’ŒçµæŸæ¨™è¨˜ï¼‰ã€‚\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|user|> How do I create a RESTful API in Java?<|end|><|assistant|> Creating '\n",
      " 'an efficient and secure Restfull Api (REST) using the Spring Boot framework '\n",
      " \"involves several steps. Here's how you can get started:\\n\"\n",
      " '```java  java   import org.*; // Import necessary packages for your project, '\n",
      " 'such as spring-boot libraries etc..import com.*;// Your domain classes or '\n",
      " 'DTO imports here...public class MyApiApplication {    public static void '\n",
      " 'main(String[] args){        ApplicationContext ctx = new '\n",
      " 'AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity '\n",
      " 'httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").')\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åªå–å¾—ç”Ÿæˆçš„æ–‡å­—, å³ `<|assistant|>` ä¹‹å¾Œçš„æ–‡å­—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Creating an efficient and secure Restfull Api (REST) using the Spring Boot '\n",
      " \"framework involves several steps. Here's how you can get started:\\n\"\n",
      " '```java  java   import org.*; // Import necessary packages for your project, '\n",
      " 'such as spring-boot libraries etc..import com.*;// Your domain classes or '\n",
      " 'DTO imports here...public class MyApiApplication {    public static void '\n",
      " 'main(String[] args){        ApplicationContext ctx = new '\n",
      " 'AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity '\n",
      " 'httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").')\n"
     ]
    }
   ],
   "source": [
    "# åªå–å¾—ç”Ÿæˆçš„æ–‡å­—, å³ <|assistant|> ä¹‹å¾Œçš„æ–‡å­—\n",
    "pprint(output.split('<|assistant|>')[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ‰¹æ¬¡è™•ç†æ¨¡å‹è¡¨ç¾\n",
    "\n",
    "åˆæ­¥äº†è§£å¦‚ä½•ç”Ÿæˆæ¨¡å‹çš„å›æ‡‰ï¼Œæˆ‘å€‘å°‡å®šç¾©ä¸€å€‹ `generate()` å‡½æ•¸ä¾†ç”Ÿæˆæ¨¡å‹çš„å›æ‡‰ã€‚é€™å€‹å‡½æ•¸æ¥å—ä¸€å€‹è¼¸å…¥æ–‡æœ¬ï¼Œä¸¦ç”Ÿæˆæ¨¡å‹çš„å›æ‡‰ã€‚è—‰ç”±é€™å€‹å‡½æ•¸ï¼Œæˆ‘å€‘å¯ä»¥æ‰¹æ¬¡è™•ç†è³‡æ–™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ä»¥ä¸Šç¨‹å¼ç¢¼æ•´ç†æˆä¸€å€‹å‡½å¼ï¼Œæ–¹ä¾¿æˆ‘å€‘æ‰¹æ¬¡è™•ç†è³‡æ–™\n",
    "def generator(x, model):\n",
    "  tokenized_input = instruction_formatter(x, tokenize=True)\n",
    "  output_ids = model.generate(\n",
    "    **tokenized_input,\n",
    "    temperature=config.temperature,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    repetition_penalty=config.repetition_penalty,\n",
    "  )\n",
    "  output = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "  return output.split('<|assistant|>')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# é€™å€‹æ­¥é©Ÿå¯èƒ½æœƒèŠ±è²»ä¸€äº›æ™‚é–“ï¼Œæ‰€ä»¥æˆ‘å€‘åªè™•ç†å‰ first_n_data ç­†è³‡æ–™\n",
    "first_n_dataset = dataset['test'].select(range(first_n_data))\n",
    "\n",
    "# ç§»é™¤ messages æ¬„ä½\n",
    "first_n_dataset = first_n_dataset.remove_columns('messages')\n",
    "\n",
    "# é€éé è¨“ç·´æ¨¡å‹ç”Ÿæˆå›æ‡‰ï¼Œå°‡å…¶æ–°å¢åˆ° pt_response æ¬„ä½ä¸­\n",
    "pt_response = []\n",
    "for x in first_n_dataset:\n",
    "  pt_response.append(generator(x, model))\n",
    "\n",
    "first_n_df = pd.DataFrame(first_n_dataset)\n",
    "first_n_df['pt_response'] = pt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>pt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "      <td>Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  ğŸ“    **Graph Class Definition**     ```cpp      #include &lt;iostream&gt;       // For input/output operations        class Vertex {          public :            int id;              std::vector&lt;Vertex* &gt; neighbors ;             };         /* A vertex object contains its unique identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "      <td>Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attentionâ€”think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; ğŸ“   ```bash    $ sudo apt install node    â¡ï¸ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "      <td>The terms \"hash-table\" (or simply, â€œhashtableâ€) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \\\n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}   \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}   \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pt_response  \n",
       "0                                                                                                               Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").  \n",
       "1                                                                                                         Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  ğŸ“    **Graph Class Definition**     ```cpp      #include <iostream>       // For input/output operations        class Vertex {          public :            int id;              std::vector<Vertex* > neighbors ;             };         /* A vertex object contains its unique identifier  \n",
       "2  Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attentionâ€”think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult  \n",
       "3                                                                                                                                                                      Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; ğŸ“   ```bash    $ sudo apt install node    â¡ï¸ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash  \n",
       "4            The terms \"hash-table\" (or simply, â€œhashtableâ€) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é¡¯ç¤ºé è¨“ç·´æ¨¡å‹é æ¸¬çµæœ\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "first_n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¨“ç·´æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA çš„è¨“ç·´ç­–ç•¥\n",
    "\n",
    "LoRAï¼ˆLow-Rank Adaptationï¼‰æ˜¯ä¸€ç¨®ç”¨æ–¼è¨“ç·´å¤§å‹èªè¨€æ¨¡å‹çš„æŠ€è¡“ï¼Œæ—¨åœ¨æé«˜è¨“ç·´æ•ˆç‡ä¸¦æ¸›å°‘è¨ˆç®—è³‡æºçš„éœ€æ±‚ã€‚ä»¥ä¸‹æ˜¯ç‚ºä½•éœ€è¦é€éLoRAè¨“ç·´çš„ä¸€äº›åŸå› ï¼š\n",
    "\n",
    "* é™ä½è¨ˆç®—æˆæœ¬ï¼šLoRA é€šéå°‡æ¨¡å‹çš„æ¬Šé‡çŸ©é™£åˆ†è§£ç‚ºä½ç§©çŸ©é™£ï¼Œé¡¯è‘—æ¸›å°‘äº†åƒæ•¸çš„æ•¸é‡ï¼Œå¾è€Œé™ä½äº†è¨ˆç®—æˆæœ¬å’Œå…§å­˜éœ€æ±‚ã€‚\n",
    "\n",
    "* åŠ é€Ÿè¨“ç·´é€Ÿåº¦ï¼šç”±æ–¼åƒæ•¸æ•¸é‡æ¸›å°‘ï¼ŒLoRA å¯ä»¥åŠ é€Ÿæ¨¡å‹çš„è¨“ç·´éç¨‹ï¼Œä½¿å¾—åœ¨ç›¸åŒçš„ç¡¬ä»¶è³‡æºä¸‹èƒ½å¤ æ›´å¿«åœ°å®Œæˆè¨“ç·´ã€‚\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å€‘å…ˆä¾†è§€å¯Ÿé è¨“ç·´æ¨¡å‹å¯è¨“ç·´çš„åƒæ•¸é‡ï¼Œå…¶æ•¸é‡ç›¸ç•¶é¾å¤§ï¼Œæ‰€ä»¥éœ€è¦é€é Low Rank Adaptation (LoRA) ä¾†é™ä½åƒæ•¸é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 3,821,079,552, Trainable Parameters: 3,821,079,552\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹é è¨“ç·´æ¨¡å‹å¯è¨“ç·´çš„åƒæ•¸é‡ï¼Œå…¶æ•¸é‡ç›¸ç•¶é¾å¤§ï¼Œæ‰€ä»¥éœ€è¦é€é Low Rank Adaptation (LoRA) ä¾†é™ä½åƒæ•¸é‡\n",
    "print('Parameters: {:,}, Trainable Parameters: {:,}'.format(\n",
    "  model.num_parameters(),\n",
    "  model.num_parameters(only_trainable=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA é…ç½®\n",
    "\n",
    "* `task_type`: TaskType.CAUSAL_LM æŒ‡å®šä»»å‹™é¡å‹ç‚ºå› æœèªè¨€æ¨¡å‹ (Causal Language Model)ã€‚\n",
    "\n",
    "* `rank`: æ˜¯ä½ç§©çŸ©é™£çš„ç§©(rank)ï¼Œå®ƒæ±ºå®šäº† LoRA å±¤çš„åƒæ•¸æ•¸é‡ã€‚è¼ƒä½çš„ `r` å€¼æ„å‘³è‘—è¼ƒå°‘çš„åƒæ•¸ï¼Œå¾è€Œæ¸›å°‘äº†æ¨¡å‹çš„è¨ˆç®—å’Œå­˜å„²éœ€æ±‚ã€‚å…·é«”ä¾†èªªï¼ŒLoRA é€šéå°‡å…¨é€£æ¥å±¤çš„æ¬Šé‡çŸ©é™£åˆ†è§£ç‚ºå…©å€‹ä½ç§©çŸ©é™£ä¾†å¯¦ç¾åƒæ•¸é«˜æ•ˆåŒ–ã€‚`r` å€¼è¶Šå°ï¼Œé€™å…©å€‹ä½ç§©çŸ©é™£çš„ç¶­åº¦è¶Šå°ï¼Œé€™å€‹ç·´ç¿’æˆ‘å€‘æ¡ç”¨ 128ã€‚\n",
    "\n",
    "* `lora_alpha`: æ˜¯ä¸€å€‹ç¸®æ”¾å› å­ï¼Œç”¨æ–¼èª¿æ•´ LoRA å±¤çš„è¼¸å‡ºã€‚å®ƒæ§åˆ¶äº†ä½ç§©çŸ©é™£çš„å½±éŸ¿åŠ›ã€‚è¼ƒé«˜çš„ `lora_alpha` å€¼æœƒå¢åŠ  LoRA å±¤çš„å½±éŸ¿åŠ›ï¼Œä¹Ÿå°±æ˜¯èªªå€¼è¶Šé«˜ï¼Œè¶Šå®¹æ˜“æŠŠå¤§æ¨¡å‹æ—¢æœ‰çš„èƒ½åŠ›çµ¦è¦†è“‹æ‰ã€‚å…·é«”ä¾†èªªï¼ŒLoRA å±¤çš„è¼¸å‡ºæœƒä¹˜ä»¥é€™å€‹ç¸®æ”¾å› å­ï¼Œé€™å€‹ç·´ç¿’æˆ‘å€‘æ¡ç”¨å¸¸è¦‹çš„æ¯”ä¾‹ç‚º `rank` çš„å…©å€ã€‚\n",
    "\n",
    "* `lora_dropout`: æ˜¯ä¸€å€‹ä¸Ÿæ£„ç‡ï¼Œç”¨æ–¼åœ¨è¨“ç·´éç¨‹ä¸­éš¨æ©Ÿä¸Ÿæ£„ LoRA å±¤çš„ä¸€éƒ¨åˆ†è¼¸å‡ºã€‚é€™æœ‰åŠ©æ–¼é˜²æ­¢éæ“¬åˆï¼Œä¸¦æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œ`lora_dropout` è¨­ç½®ç‚º 0.1 è¡¨ç¤ºåœ¨æ¯æ¬¡å‰å‘å‚³æ’­ä¸­ï¼Œæœ‰ 10% çš„ LoRA å±¤è¼¸å‡ºæœƒè¢«éš¨æ©Ÿè¨­ç½®ç‚ºé›¶ã€‚\n",
    "\n",
    "* `target_module`: æŒ‡å®šäº†æ‡‰ç”¨ LoRA çš„ç›®æ¨™æ¨¡å¡Šã€‚é€™é€šå¸¸æ˜¯æ¨¡å‹ä¸­çš„æŸäº›ç‰¹å®šå±¤æˆ–å­æ¨¡å¡Šï¼Œä¾‹å¦‚ Transformer æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›å±¤ï¼Œå¯ä»¥é€é `model.named_parameters` æŸ¥çœ‹ã€‚é€šéæŒ‡å®š `target_module`ï¼Œä½ å¯ä»¥éˆæ´»åœ°é¸æ“‡åœ¨å“ªäº›å±¤æ‡‰ç”¨ LoRAï¼Œä»¥ä¾¿åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ™‚æ¸›å°‘åƒæ•¸æ•¸é‡ã€‚\n",
    "\n",
    "> å»£ç‚ºå‘¨çŸ¥çš„æ¨¡å‹ç•¶æœªæŒ‡å®š `target_module`ï¼Œé€é `get_peft_model` åŠ è¼‰ Lora é©é…æ¨¡å‹æ™‚ï¼Œæœƒè‡ªå‹•è¨­å®šã€‚\n",
    "> å¯ä»¥å…ˆå˜—è©¦ä¸æŒ‡å®šï¼Œè‹¥å‡ºç¾éŒ¯èª¤å†è©¦è‘—è¨­å®šæ³¨æ„åŠ›ç›¸é—œçš„åƒæ•¸å±¤ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path=None,\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules={'qkv_proj'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "# LoRA é…ç½®\n",
    "lora_config = LoraConfig(\n",
    "  task_type=TaskType.CAUSAL_LM,\n",
    "  r=config.rank,\n",
    "  lora_alpha=config.lora_alpha,\n",
    "  lora_dropout=config.lora_dropout,\n",
    "  # Phi3ForCausalLM need to specify the target_modules beforehand\n",
    "  target_modules=['qkv_proj'],\n",
    ")\n",
    "\n",
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åŠ è¼‰ LoRA é©é…æ¨¡å‹\n",
    "\n",
    "æ­é…é è¨“æ¨¡å‹åŠ LoRA é…ç½®ï¼Œæˆ‘å€‘å¯ä»¥åŠ è¼‰ LoRA é©é…æ¨¡å‹ã€‚æˆ‘å€‘å¯ä»¥è§€å¯Ÿå—åˆ°é™ç¶­å½±éŸ¿çš„æ¨¡å‹å±¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# åŠ è¼‰ LoRA é©é…æ¨¡å‹\n",
    "peft_model = get_peft_model(\n",
    "  model, # é è¨“ç·´æ¨¡å‹\n",
    "  lora_config, # LoRA é…ç½®\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path='microsoft/Phi-3.5-mini-instruct',\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules={'qkv_proj'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA é©é…æ¨¡å‹\n",
    "\n",
    "åŠ è¼‰ LoRA é©é…æ¨¡å‹å¾Œ, è§€å¯Ÿå— LoRA å½±éŸ¿çš„æ¨¡å‹åƒæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3SdpaAttention(\n",
       "              (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "              (qkv_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=128, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=128, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "              (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”±æ–¼æˆ‘å€‘æŒ‡å®šçš„ `target_module` æ˜¯ `qkv_proj`, å› æ­¤æ‰€æœ‰æ³¨æ„åŠ›å±¤å—åˆ° LoRA çš„å½±éŸ¿ã€‚\n",
    "\n",
    "```json\n",
    "  (qkv_proj): lora.Linear(\n",
    "    (base_layer): Linear(in_features=3072, out_features=9216, bias=False)\n",
    "    (lora_dropout): ModuleDict(\n",
    "      (default): Dropout(p=0.05, inplace=False)\n",
    "    )\n",
    "    (lora_A): ModuleDict(\n",
    "      (default): Linear(in_features=3072, out_features=128, bias=False)\n",
    "    )\n",
    "    (lora_B): ModuleDict(\n",
    "      (default): Linear(in_features=128, out_features=9216, bias=False)\n",
    "    )\n",
    "    (lora_embedding_A): ParameterDict()\n",
    "    (lora_embedding_B): ParameterDict()\n",
    "    (lora_magnitude_vector): ModuleDict()\n",
    "  )\n",
    "```              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### èª¿æ•´ LoRA ç²¾åº¦\n",
    "\n",
    "LoRA é©é…æ¨¡å‹çš„ç²¾åº¦æ˜¯ `torch.float32`ï¼Œæˆ‘å€‘å¯ä»¥é€é `model.half()` å°‡å…¶è½‰æ›ç‚ºåŠç²¾åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if config.torch_dtype == torch.float16 or config.torch_dtype == torch.bfloat16:\n",
    "  peft_model = peft_model.half() # è½‰æ›ç‚ºåŠç²¾åº¦æµ®é»æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.0.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.0.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.1.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.1.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.2.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.2.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.3.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.3.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.4.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.4.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.5.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.5.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.6.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.6.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.7.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.7.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.8.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.8.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.9.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.9.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.10.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.10.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.11.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.11.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.12.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.12.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.13.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.13.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.14.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.14.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.15.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.15.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.16.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.16.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.17.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.17.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.18.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.18.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.19.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.19.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.20.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.20.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.21.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.21.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.22.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.22.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.23.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.23.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.24.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.24.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.25.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.25.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.26.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.26.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.27.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.27.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.28.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.28.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.29.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.29.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.30.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.30.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
      "base_model.model.model.layers.31.mlp.gate_up_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight: torch.float16\n",
      "base_model.model.model.layers.31.input_layernorm.weight: torch.float16\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: torch.float16\n",
      "base_model.model.model.norm.weight: torch.float16\n",
      "base_model.model.lm_head.weight: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# ç²å– LoRA æ¨¡å‹åƒæ•¸åç¨±åŠå‹æ…‹ï¼Œç¢ºèªæ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æµ®é»æ•¸\n",
    "for name, param in peft_model.named_parameters():\n",
    "  print(f'{name}: {param.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¶“é `model.half()` è½‰æ›å¾Œï¼ŒLoRA é©é…æ¨¡å‹çš„æ¬Šé‡ä¹Ÿè®ŠæˆåŠç²¾åº¦ã€‚\n",
    "\n",
    "```shell\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight: torch.float16\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight: torch.float16\n",
    "base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight: torch.float16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¨“ç·´åƒæ•¸é‡ä¹Ÿå¾åŸå…ˆ 3B å¤§å¤§æ¸›å°‘ç‚º 50Mã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 50,331,648 || all params: 3,871,411,200 || trainable%: 1.3001\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹å¯è¨“ç·´çš„åƒæ•¸é‡\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è© å”±æ ¼å¼åŒ– (Prompt Formatting)\n",
    "\n",
    "æœ‰åˆ¥æ–¼å…ˆå‰çš„è© å”±æ ¼å¼ï¼Œé€™æ¬¡æˆ‘å€‘å°‡åŒ…å« `assistant` çš„å›æ‡‰ï¼Œä»¥ä¾¿ä½œç‚ºæ¨™æ³¨è³‡æ–™ä¾›æ¨¡å‹è¨“ç·´ã€‚ç”±æ–¼å·²ç¶“åŒ…å« `assistant`ï¼Œé€™æ¬¡æˆ‘å€‘æŒ‡å®š `add_generation_prompt` ç‚º `False`ï¼Œçœå»å›æ‡‰é–‹å§‹çš„æ¨™è¨˜ã€‚\n",
    "\n",
    "å¦ä¸€å€‹å·®ç•°æ˜¯ï¼Œé€™å€‹å‡½å¼é è¨­ä¸æœƒé€²è¡Œ tokenizeï¼Œæœƒç›´æ¥å›å‚³åŸå§‹æ–‡å­—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def instruction_completion_formatter(x, tokenize: bool = False):\n",
    "  return tokenizer.apply_chat_template(\n",
    "    x['messages'],\n",
    "    tokenize=tokenize,\n",
    "    add_generation_prompt=False,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|user|>\\n'\n",
      " 'What is the difference between a hash set and a hash map?<|end|>\\n'\n",
      " '<|assistant|>\\n'\n",
      " 'A hash set is a collection of unique elements, while a hash map is a '\n",
      " 'collection of key-value pairs.<|end|>\\n'\n",
      " '<|endoftext|>')\n"
     ]
    }
   ],
   "source": [
    "pprint(instruction_completion_formatter(dataset['train'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è³‡æ–™æ ¡å°å™¨ (Data Collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# å®šç¾©å›æ‡‰é–‹å§‹çš„æ¨™è¨˜\n",
    "response_template = '<|assistant|>'\n",
    "\n",
    "# è¨­å®š DataCollatorForCompletionOnlyLM\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "  tokenizer=tokenizer,\n",
    "  response_template=response_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[32010,  1724,   338,   278,  4328,  1546,   263,  6608,   731,   322,\n",
      "           263,  6608,  2910, 29973, 32007, 32001,   319,  6608,   731,   338,\n",
      "           263,  4333,   310,  5412,  3161, 29892,  1550,   263,  6608,  2910,\n",
      "           338,   263,  4333,   310,  1820, 29899,  1767, 11000, 29889, 32007,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  2656,   263,  1051,\n",
      "           297,  5132, 29973, 32007, 32001,  8221, 29892,   306,  2609,  3867,\n",
      "          8720,   775,   470,   775,  9830, 27421, 29889,   306,   508,  6985,\n",
      "           366,   411,   278,  5155, 29889, 32007, 32000, 32000, 32000, 32000,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  1284,   278, 14176,\n",
      "          3619,  8572,   272,   313, 29954,  6530, 29897,   297,  8286, 29973,\n",
      "         32007, 32001,  8221, 29892,   306,  2609,  3867,  8720,   775,   470,\n",
      "           775,  9830, 27421, 29889,   306,   508,  6985,   366,   411,   278,\n",
      "          5155, 29889, 32007, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  3588,   263,  1347,\n",
      "           304,   385,  6043,   297,  8286, 29973, 32007, 32001,  8221, 29892,\n",
      "           306,  2609,  3867,  8720,   775,   470,   775,  9830, 27421, 29889,\n",
      "           306,   508,  6985,   366,   411,   278,  5155, 29889, 32007, 32000,\n",
      "         32000, 32000, 32000, 32000],\n",
      "        [32010,  1815,   366,  2436,   263,   740,   304,  1284,   278,  7472,\n",
      "           995,   297,   385,  1409,   297,   315,  1817, 29973, 32007, 32001,\n",
      "          8221, 29892,   306,  2609,  3867,  8720,   775,   470,   775,  9830,\n",
      "         27421, 29889,   306,   508,  6985,   366,   411,   278,  5155, 29889,\n",
      "         32007, 32000, 32000, 32000]]),\n",
      " 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,   319,  6608,   731,   338,\n",
      "           263,  4333,   310,  5412,  3161, 29892,  1550,   263,  6608,  2910,\n",
      "           338,   263,  4333,   310,  1820, 29899,  1767, 11000, 29889, 32007,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  8221, 29892,   306,  2609,  3867,\n",
      "          8720,   775,   470,   775,  9830, 27421, 29889,   306,   508,  6985,\n",
      "           366,   411,   278,  5155, 29889, 32007,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  8221, 29892,   306,  2609,  3867,  8720,   775,   470,\n",
      "           775,  9830, 27421, 29889,   306,   508,  6985,   366,   411,   278,\n",
      "          5155, 29889, 32007,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  8221, 29892,\n",
      "           306,  2609,  3867,  8720,   775,   470,   775,  9830, 27421, 29889,\n",
      "           306,   508,  6985,   366,   411,   278,  5155, 29889, 32007,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          8221, 29892,   306,  2609,  3867,  8720,   775,   470,   775,  9830,\n",
      "         27421, 29889,   306,   508,  6985,   366,   411,   278,  5155, 29889,\n",
      "         32007,  -100,  -100,  -100]])}\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤º DataCollatorForCompletionOnlyLM çš„è¼¸å‡º, æ¨™ç±¤ä»¥ -100 è¡¨ç¤ºåœ¨æå¤±å‡½æ•¸ä¸­ä¸æœƒè¢«è€ƒæ…®\n",
    "batch = data_collator([instruction_completion_formatter(dataset['train'][i], True) for i in range(first_n_data)])\n",
    "pprint(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"input: ['<|user|>', 'What', 'is', 'the', 'difference', 'between', 'a', \"\n",
      " \"'hash', 'set', 'and', 'a', 'hash', 'map', '?', '<|end|>', '<|assistant|>', \"\n",
      " \"'A', 'hash', 'set', 'is', 'a', 'collection', 'of', 'unique', 'elements', \"\n",
      " \"',', 'while', 'a', 'hash', 'map', 'is', 'a', 'collection', 'of', 'key', '-', \"\n",
      " \"'value', 'pairs', '.', '<|end|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', 'A', 'hash', 'set', 'is', 'a', 'collection', 'of', 'unique', \"\n",
      " \"'elements', ',', 'while', 'a', 'hash', 'map', 'is', 'a', 'collection', 'of', \"\n",
      " \"'key', '-', 'value', 'pairs', '.', '<|end|>', '-', '-', '-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'sort', \"\n",
      " \"'a', 'list', 'in', 'Python', '?', '<|end|>', '<|assistant|>', 'Sorry', ',', \"\n",
      " \"'I', 'cannot', 'provide', 'programming', 'code', 'or', 'code', 'sni', \"\n",
      " \"'ppets', '.', 'I', 'can', 'assist', 'you', 'with', 'the', 'questions', '.', \"\n",
      " \"'<|end|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', 'programming', 'code', \"\n",
      " \"'or', 'code', 'sni', 'ppets', '.', 'I', 'can', 'assist', 'you', 'with', \"\n",
      " \"'the', 'questions', '.', '<|end|>', '-', '-', '-', '-', '-', '-', '-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'find', \"\n",
      " \"'the', 'greatest', 'common', 'divis', 'or', '(', 'G', 'CD', ')', 'in', \"\n",
      " \"'JavaScript', '?', '<|end|>', '<|assistant|>', 'Sorry', ',', 'I', 'cannot', \"\n",
      " \"'provide', 'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', \"\n",
      " \"'can', 'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', \"\n",
      " \"'<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', \"\n",
      " \"'provide', 'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', \"\n",
      " \"'can', 'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'convert', \"\n",
      " \"'a', 'string', 'to', 'an', 'integer', 'in', 'JavaScript', '?', '<|end|>', \"\n",
      " \"'<|assistant|>', 'Sorry', ',', 'I', 'cannot', 'provide', 'programming', \"\n",
      " \"'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', 'assist', 'you', \"\n",
      " \"'with', 'the', 'questions', '.', '<|end|>', '<|endoftext|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-', '-', '-', \"\n",
      " \"'-', '-']\")\n",
      "(\"input: ['<|user|>', 'Can', 'you', 'write', 'a', 'function', 'to', 'find', \"\n",
      " \"'the', 'maximum', 'value', 'in', 'an', 'array', 'in', 'C', '++', '?', \"\n",
      " \"'<|end|>', '<|assistant|>', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', \"\n",
      " \"'<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\")\n",
      "(\"label: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', \"\n",
      " \"'-', '-', '-', '-', '-', '-', '-', 'Sorry', ',', 'I', 'cannot', 'provide', \"\n",
      " \"'programming', 'code', 'or', 'code', 'sni', 'ppets', '.', 'I', 'can', \"\n",
      " \"'assist', 'you', 'with', 'the', 'questions', '.', '<|end|>', '-', '-', '-']\")\n"
     ]
    }
   ],
   "source": [
    "# é€é Tokenizer çš„ decode æ–¹æ³•å°‡ ID è½‰æ›å›æ–‡å­—ï¼Œä¸¦åˆ—æ¨™ç±¤é¡¯ç¤ºå‡ºä¾†\n",
    "for idx in range(first_n_data):\n",
    "  input_ids = batch['input_ids'][idx]\n",
    "  labels_ids = batch['labels'][idx]\n",
    "  input = [tokenizer.decode(id) for id in input_ids]\n",
    "  labels = ['-'] * len(input_ids)\n",
    "  for i, id in enumerate(labels_ids):\n",
    "    if id != -100:\n",
    "      labels[i] = tokenizer.decode(id)\n",
    "  pprint(f'input: {input}')\n",
    "  pprint(f'label: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ å¯ä»¥æ¸…æ¥šè§€å¯Ÿåˆ°ï¼Œæå¤±å‡½æ•¸ä¸æœƒå»é—œæ³¨åŒ…å« `<|assistant|>` ä¹‹å‰çš„éƒ¨åˆ†ï¼Œé€™æ¨£å¯ä»¥è®“æ¨¡å‹å°ˆæ³¨æ–¼ç”Ÿæˆ `<|assistant|>` ä¹‹å¾Œçš„å›æ‡‰ã€‚\n",
    "\n",
    "è€ƒé‡æ‰¹æ¬¡è¨“ç·´ä¸åŒé•·åº¦çš„åºåˆ—éœ€è¦å¡«å……åˆ°ç›¸åŒçš„é•·åº¦ï¼Œä»¥ä¾¿èƒ½å¤ åœ¨åŒä¸€æ‰¹æ¬¡ä¸­é€²è¡Œè™•ç†ã€‚Data Collator è‡ªå‹•é€²è¡Œé©ç•¶çš„å¡«å……ï¼Œå¡«å……çš„éƒ¨åˆ†äº¦ä¸æœƒåƒèˆ‡æå¤±è¨ˆç®—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¨“ç·´åƒæ•¸è¨­å®š\n",
    "\n",
    "ç”¨æ–¼è¨­å®šè¨“ç·´éç¨‹ä¸­çš„å„ç¨®åƒæ•¸ï¼Œå¦‚å­¸ç¿’ç‡ã€æ‰¹æ¬¡å¤§å°ã€æ¢¯åº¦ç´¯ç©æ­¥æ•¸ã€è¨“ç·´ epoch æ•¸ã€æ¬Šé‡è¡°æ¸›ç­‰ã€‚\n",
    "\n",
    "* `output_dir` æŒ‡å®šäº†è¨“ç·´è¼¸å‡ºçš„ç›®éŒ„ã€‚\n",
    "* `logging_steps` è¨“ç·´æ™‚çš„æ—¥èªŒæ­¥æ•¸ï¼Œæ±ºå®šæ¯éš”å¤šå°‘æ­¥è¼¸å‡ºä¸€æ¬¡è¨“ç·´æ—¥èªŒã€‚\n",
    "* `eval_strategy` å’Œ `save_strategy` è¨­å®šç‚º 'steps'ï¼Œè¡¨ç¤ºæ¯ `logging_steps` å€‹ steps éƒ½æœƒé€²è¡Œè©•ä¼°å’Œå„²å­˜ã€‚\n",
    "* `load_best_model_at_end` è¨­å®šç‚º `True`ï¼Œè¡¨ç¤ºè¨“ç·´çµæŸå¾Œæœƒè¼‰å…¥æœ€ä½³æ¨¡å‹ã€‚\n",
    "* `report_to` ç¦ç”¨ wandb å ±å‘Šï¼Œé©ç”¨æ–¼ Colab ç’°å¢ƒï¼Œé¿å…éœ€è¦é…ç½® wandbã€‚\n",
    "* `adam_epsilon` Adam å„ªåŒ–å™¨çš„ epsilon å€¼ï¼Œç•¶ä½¿ç”¨åŠç²¾åº¦æµ®é»æ•¸æ™‚éœ€è¦è¨­å®šè¼ƒå¤§çš„å€¼ä»¥ç©©å®šè¨“ç·´ã€‚\n",
    "* `packing` ç•¶ä½¿ç”¨ DataCollatorForCompletionOnlyLM æ™‚ç¦ç”¨ packingï¼Œé€™æ˜¯ç‰¹å®šæ–¼æ•¸æ“šæ•´ç†å™¨çš„è¨­å®šã€‚\n",
    "* `save_total_limit` æœ€å¤šå„²å­˜ 5 å€‹ checkpointsï¼Œæ§åˆ¶å„²å­˜çš„æ¨¡å‹æª”æ¡ˆæ•¸é‡ä»¥ç¯€çœç£ç¢Ÿç©ºé–“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "  output_dir='sample_data/train_output_qa', # è¨“ç·´è¼¸å‡ºç›®éŒ„\n",
    "  learning_rate=config.lr, # å­¸ç¿’ç‡\n",
    "  per_device_train_batch_size=config.batch_size, # æ¯å€‹è¨­å‚™çš„è¨“ç·´æ‰¹æ¬¡å¤§å°\n",
    "  per_device_eval_batch_size=config.batch_size, # æ¯å€‹è¨­å‚™çš„è©•ä¼°æ‰¹æ¬¡å¤§å°\n",
    "  gradient_accumulation_steps=config.gradient_accumulation_steps, # æ¢¯åº¦ç´¯ç©æ­¥æ•¸\n",
    "  logging_steps=50, # è¨“ç·´æ™‚çš„æ—¥èªŒæ­¥æ•¸, é è¨­æ¯ 500 æ­¥è¼¸å‡ºä¸€æ¬¡æ—¥èªŒ\n",
    "  num_train_epochs=config.epochs, # è¨“ç·´çš„ç¸½ epoch æ•¸\n",
    "  weight_decay=config.weight_decay, # æ¬Šé‡è¡°æ¸›\n",
    "  eval_strategy='steps', # è©•ä¼°ç­–ç•¥\n",
    "  save_strategy='steps', # å„²å­˜ç­–ç•¥\n",
    "  load_best_model_at_end=True,\n",
    "  report_to='none', # ç¦ç”¨ wandb å ±å‘Š (Colab ç’°å¢ƒé è¨­éœ€è¦ wandb)\n",
    "  adam_epsilon=config.adam_epsilon, # ç•¶ä½¿ç”¨åŠç²¾åº¦æµ®é»æ•¸æ™‚ï¼Œéœ€è¦è¨­å®šè¼ƒå¤§çš„ adam epsilon\n",
    "  packing=False, # ç•¶ä½¿ç”¨ DataCollatorForCompletionOnlyLM æ™‚ç¦ç”¨ packing\n",
    "  save_total_limit=5, # æœ€å¤šå„²å­˜ 5 å€‹ checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¨“ç·´å™¨åˆå§‹åŒ–\n",
    "\n",
    "ç”¨æ–¼åˆå§‹åŒ–è¨“ç·´å™¨ï¼Œä¸¦é–‹å§‹è¨“ç·´æ¨¡å‹ã€‚\n",
    "\n",
    "* `model` æ˜¯è¦è¨“ç·´çš„æ¨¡å‹ã€‚\n",
    "* `tokenizer` æ˜¯ç”¨æ–¼è™•ç†æ–‡æœ¬çš„åˆ†è©å™¨ã€‚\n",
    "* `train_dataset` æ˜¯è¨“ç·´æ•¸æ“šé›†ã€‚\n",
    "* `formatting_func` æ˜¯ç”¨æ–¼æ ¼å¼åŒ–æ•¸æ“šçš„å‡½æ•¸ã€‚\n",
    "* `data_collator` æ˜¯ç”¨æ–¼æ•´ç†æ•¸æ“šçš„æ•¸æ“šæ•´ç†å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/hkxkfjqd58j9t_718vfr4tjw0000gn/T/ipykernel_6831/1766244151.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 3288.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 4697.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=peft_model, # è¦è¨“ç·´çš„æ¨¡å‹\n",
    "    tokenizer=tokenizer, # ä½¿ç”¨çš„åˆ†è©å™¨\n",
    "    args=training_args, # è¨“ç·´åƒæ•¸\n",
    "    train_dataset=dataset['train'], # è¨“ç·´æ•¸æ“šé›†\n",
    "    eval_dataset=dataset['validation'], # é©—è­‰æ•¸æ“šé›†\n",
    "    formatting_func=instruction_completion_formatter, # æ ¼å¼åŒ–å‡½æ•¸\n",
    "    data_collator=data_collator, # æ•¸æ“šæ•´ç†å™¨\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é–‹å§‹è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [475/475 12:33, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.663794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.590753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.789255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.888242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.992421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.012923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.019349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.021163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.021307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=475, training_loss=0.06120919820019289, metrics={'train_runtime': 758.746, 'train_samples_per_second': 2.504, 'train_steps_per_second': 0.626, 'total_flos': 1937268855853056.0, 'train_loss': 0.06120919820019289, 'epoch': 25.0})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é–‹å§‹è¨“ç·´ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¿å­˜ LoRA æ¨¡å‹åƒæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# ä¿å­˜ Lora å‚æ•°\n",
    "peft_model.save_pretrained(\n",
    "  config.saved_lora_path,\n",
    "  # warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
    "  save_embedding_layers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä¿å­˜ Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer_config.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/special_tokens_map.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer.model',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/added_tokens.json',\n",
       " 'saved_model/fine-tune-a8013a93-85f5-4b57-9a85-385b291713e2/tokenizer.json')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¿å­˜ Tokenizer\n",
    "tokenizer.save_pretrained(config.saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é‡‹æ”¾è³‡æº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import garbage collector\n",
    "import gc\n",
    "\n",
    "# é‡‹æ”¾ GPU è¨˜æ†¶é«”\n",
    "del trainer\n",
    "del tokenizer\n",
    "\n",
    "peft_model.to('cpu')\n",
    "del peft_model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è©•ä¼°å¾®èª¿æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼‰å…¥å¾®èª¿åˆ†è©å™¨ (Tokenizer)\n",
    "\n",
    "å¾å·²ç¶“å®Œæˆè¨“ç·´çš„æ¨¡å‹å–å¾— Tokenizerï¼Œå¯ä»¥ç•™æ„é€™å€‹è¨“ç·´æ™‚ä¿å­˜ä¸‹ä¾†çš„ Tokenizer ä»ä¿æœ‰è¨“ç·´æ™‚çš„è¨­å®šï¼ŒåŒ…æ¶µ `pad_token` å’Œ `padding_side`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.saved_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼‰å…¥å¾®èª¿å¾Œæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ft_model = PeftModel.from_pretrained(\n",
    "  model, # é è¨“ç·´æ¨¡å‹\n",
    "  config.saved_lora_path, # LoRA é©é…æ¨¡å‹\n",
    "  # é€™å€‹åƒæ•¸ç”¨æ–¼å„ªåŒ–å…§å­˜ä½¿ç”¨ï¼Œæ¸›å°‘æ¨¡å‹åŠ è¼‰æ™‚çš„ CPU å…§å­˜ä½”ç”¨ï¼Œç‰¹åˆ¥æ˜¯åœ¨å…§å­˜æœ‰é™çš„ç’°å¢ƒä¸­éå¸¸æœ‰ç”¨ã€‚\n",
    "  low_cpu_mem_usage=True,\n",
    "  torch_dtype=config.torch_dtype,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning å¾Œçš„è¡¨ç¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "# é€éå¾®èª¿æ¨¡å‹ç”Ÿæˆå›æ‡‰ï¼Œå°‡å…¶æ–°å¢åˆ° ft_response æ¬„ä½ä¸­\n",
    "ft_response = []\n",
    "for x in first_n_dataset:\n",
    "  ft_response.append(generator(x, ft_model))\n",
    "\n",
    "first_n_df['ft_response'] = ft_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>pt_response</th>\n",
       "      <th>ft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Java?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").</td>\n",
       "      <td>Sorry, I cannot provide programming code or codes. However, I can guide you on the principles and methodologies involved. Would you like to know more about it?&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'content': 'How do I implement a graph in C++?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}</td>\n",
       "      <td>Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  ğŸ“    **Graph Class Definition**     ```cpp      #include &lt;iostream&gt;       // For input/output operations        class Vertex {          public :            int id;              std::vector&lt;Vertex* &gt; neighbors ;             };         /* A vertex object contains its unique identifier</td>\n",
       "      <td>Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}</td>\n",
       "      <td>Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attentionâ€”think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult</td>\n",
       "      <td>Synchronous programming involves operations that run in sequence, while asynchronous programming allows for tasks to be executed concurrently.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}</td>\n",
       "      <td>Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; ğŸ“   ```bash    $ sudo apt install node    â¡ï¸ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash</td>\n",
       "      <td>Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.&lt;|end|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}</td>\n",
       "      <td>{'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}</td>\n",
       "      <td>The terms \"hash-table\" (or simply, â€œhashtableâ€) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model</td>\n",
       "      <td>A hash table is a data structure that implements an associative array, while a HashMap in programming languages like Java or C++ represents a specific type of object-oriented collection.\\n&lt;|endoftext|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      user  \\\n",
       "0                                    {'content': 'How do I create a RESTful API in Java?', 'role': 'user'}   \n",
       "1                                        {'content': 'How do I implement a graph in C++?', 'role': 'user'}   \n",
       "2  {'content': 'What is the difference between synchronous and asynchronous programming?', 'role': 'user'}   \n",
       "3                                 {'content': 'How do I create a RESTful API in Node.js?', 'role': 'user'}   \n",
       "4               {'content': 'What is the difference between a hash table and a hash map?', 'role': 'user'}   \n",
       "\n",
       "                                                                                                                                                                                             assistant  \\\n",
       "0                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "1                                                                                                       {'content': 'I can't provide the code, but I can explain the structure.', 'role': 'assistant'}   \n",
       "2  {'content': 'Synchronous programming executes tasks sequentially, while asynchronous programming allows tasks to run concurrently, improving performance and responsiveness.', 'role': 'assistant'}   \n",
       "3                                                                  {'content': 'Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.', 'role': 'assistant'}   \n",
       "4                  {'content': 'A hash table is a data structure that maps keys to values using a hash function, while a hash map is a specific implementation of a hash table.', 'role': 'assistant'}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pt_response  \\\n",
       "0                                                                                                               Creating an efficient and secure Restfull Api (REST) using the Spring Boot framework involves several steps. Here's how you can get started:\\n```java  java   import org.*; // Import necessary packages for your project, such as spring-boot libraries etc..import com.*;// Your domain classes or DTO imports here...public class MyApiApplication {    public static void main(String[] args){        ApplicationContext ctx = new AnnotationConfigServletWebServerFactory().getObject();         HttpSecurity httpSecty=newHttpBasic() .and(){            antMatchers(\"/api/**\").   \n",
       "1                                                                                                         Implementing an entire Graph data structure from scratch can be quite involved, but here's how you could start with the basics of creating and managing nodes (vertices) within your own simple undirected or directed graphs using adjacency lists.\\n  Here is some basic code to get started:  ğŸ“    **Graph Class Definition**     ```cpp      #include <iostream>       // For input/output operations        class Vertex {          public :            int id;              std::vector<Vertex* > neighbors ;             };         /* A vertex object contains its unique identifier   \n",
       "2  Synchronous (sometimes referred to as \"blocking\") vs. Asynchrony are two fundamental approaches in computer science for handling tasks, especially when dealing with operations that may take an indeterminate amount of time such like I/O-bound or network requests which can significantly impact performance if not managed correctly:\\n 1) **Synchronous Programming** involves executing one operation at a given point before moving on sequentially through subsequent instructions until another task needs attentionâ€”think traditional procedural code where each step waits its predecessor'll complete execution without interruption unless explicitly programmed otherwise using mult   \n",
       "3                                                                                                                                                                      Creating an efficient and scalable Restfull Api with Express (NodeJS) involves several steps:\\n1- Setting up your project environment by installing necessary packages such as `express`, `@types/node` for type checking, body parser middleware (`bodyParser`), cors package to handle cross origin requests(`cors`) etc., using npm or yarn commands like so; ğŸ“   ```bash    $ sudo apt install node    â¡ï¸ Install NPM if not installed already      `$ curl -sL https://debianshadowcdnopseshadowdotcom//install_npm | bash   \n",
       "4            The terms \"hash-table\" (or simply, â€œhashtableâ€) often refer to essentially similar concepts in computer science but can be used slightly differently depending on context or programming language. Here's an explanation that clarifies their relationship:\\n 1 . **Hash Table** - This term refers broadly across different implementations of data structures designed for efficient lookup operations based upon key values mapped through hashing functions into buckets where these keys are stored along with associated value(ies). It encompasses various underlying mechanisms like linked lists within each bucket when collisions occur due its simplicity as conceptual model   \n",
       "\n",
       "                                                                                                                                                                                                 ft_response  \n",
       "0                                     Sorry, I cannot provide programming code or codes. However, I can guide you on the principles and methodologies involved. Would you like to know more about it?<|end|>  \n",
       "1                                                                                                     Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.<|end|>  \n",
       "2                                                      Synchronous programming involves operations that run in sequence, while asynchronous programming allows for tasks to be executed concurrently.<|end|>  \n",
       "3                                                                                                     Sorry, I cannot provide programming code or code snippets. I can assist you with the questions.<|end|>  \n",
       "4  A hash table is a data structure that implements an associative array, while a HashMap in programming languages like Java or C++ represents a specific type of object-oriented collection.\\n<|endoftext|>  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é¡¯ç¤ºå¾®èª¿æ¨¡å‹é æ¸¬çµæœ\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "first_n_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
