{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# transformers not support NumPy 2.0 yet\n",
    "!pip install -q numpy~=1.26.4 transformers~=4.46.2\n",
    "!pip install -q datasets~=3.2.0 pydantic~=2.10.4\n",
    "!pip install -q peft~=0.14.0 evaluate~=0.4.3 sacrebleu~=2.5.1\n",
    "!pip install -q pandas==2.0.3 # Downgrade pandas to a compatible version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  # Attempt to get the notebook filename from the IPython environment\n",
    "  __ipynb_file__ = os.path.splitext(os.path.basename(os.environ['JPY_SESSION_NAME']))[0]\n",
    "except (NameError, KeyError):\n",
    "  # Fallback to a default value if the variable is not found\n",
    "  __ipynb_file__ = 'default_notebook_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練 PII 遮掩模型\n",
    "\n",
    "在這個筆記本中，我們將展示如何使用 `transformers` 套件訓練 PII (個人識別資訊) 遮掩模型。我們將使用 `transformers` 套件中的 [`Seq2SeqTrainer`](https://huggingface.co/docs/evaluate/transformers_integrations#seq2seqtrainer) 類別來微調一個 Encoder-Decoder 架構的 [Flan T5](https://huggingface.co/docs/transformers/model_doc/t5) 模型。\n",
    "\n",
    "> Flan-T5: Flan is a pretraining methods that is based on prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  DataCollatorForSeq2Seq,\n",
    "  Seq2SeqTrainingArguments,\n",
    "  Seq2SeqTrainer,\n",
    "  T5ForConditionalGeneration,\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "# 載入 PEFT 相關套件\n",
    "from peft import LoraConfig, TaskType, PeftModel, get_peft_model\n",
    "\n",
    "# 檢查是否有 GPU 可以使用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ai4privacy/pii-masking-65k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/jonas/.cache/huggingface/datasets/ai4privacy___pii-masking-65k/default/0.0.0/79cf9b886f5075a98121a2f0c23f7eae201bff1b (last modified on Wed Feb 12 23:36:48 2025).\n"
     ]
    }
   ],
   "source": [
    "# The full `train` split, only 25% of dataset\n",
    "immutable_dataset = load_dataset(\"ai4privacy/pii-masking-65k\", split=\"train[:25%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 資料包含什麼？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['masked_text', 'unmasked_text', 'token_entity_labels', 'tokenised_unmasked_text'],\n",
       "    num_rows: 5397\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示原始資料中包含的 features 以及筆數\n",
    "immutable_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unmasked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "token_entity_labels",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tokenised_unmasked_text",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3dfd7b3e-453a-4dca-b1b5-edc658f673e6",
       "rows": [
        [
         "0",
         "[PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.",
         "Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.",
         "['B-PREFIX', 'I-PREFIX', 'B-FIRSTNAME', 'I-FIRSTNAME', 'B-MIDDLENAME', 'B-LASTNAME', 'I-LASTNAME', 'I-LASTNAME', 'O', 'O', 'O', 'B-JOBDESCRIPTOR', 'B-JOBTITLE', 'I-JOBTITLE', 'I-JOBTITLE', 'O', 'B-COMPANY_NAME', 'I-COMPANY_NAME', 'I-COMPANY_NAME', 'I-COMPANY_NAME', 'I-COMPANY_NAME', 'I-COMPANY_NAME', 'I-COMPANY_NAME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",
         "['mr', '.', 'adolph', '##us', 'reagan', 'z', '##ie', '##mann', ',', 'as', 'a', 'central', 'principal', 'applications', 'executive', 'at', 'mclaughlin', ',', 'nad', '##er', 'and', 'pu', '##rdy', ',', 'your', 'knowledge', 'of', 'change', 'management', 'is', 'vital', 'for', 'our', 'company', \"'\", 's', 'transformation', '.', 'we', 'request', 'you', 'to', 'create', 'a', 'change', 'management', 'strategy', '.']"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>unmasked_text</th>\n",
       "      <th>token_entity_labels</th>\n",
       "      <th>tokenised_unmasked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.</td>\n",
       "      <td>Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.</td>\n",
       "      <td>[B-PREFIX, I-PREFIX, B-FIRSTNAME, I-FIRSTNAME, B-MIDDLENAME, B-LASTNAME, I-LASTNAME, I-LASTNAME, O, O, O, B-JOBDESCRIPTOR, B-JOBTITLE, I-JOBTITLE, I-JOBTITLE, O, B-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[mr, ., adolph, ##us, reagan, z, ##ie, ##mann, ,, as, a, central, principal, applications, executive, at, mclaughlin, ,, nad, ##er, and, pu, ##rdy, ,, your, knowledge, of, change, management, is, vital, for, our, company, ', s, transformation, ., we, request, you, to, create, a, change, management, strategy, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            masked_text  \\\n",
       "0  [PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.   \n",
       "\n",
       "                                                                                                                                                                                                                                      unmasked_text  \\\n",
       "0  Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                            token_entity_labels  \\\n",
       "0  [B-PREFIX, I-PREFIX, B-FIRSTNAME, I-FIRSTNAME, B-MIDDLENAME, B-LASTNAME, I-LASTNAME, I-LASTNAME, O, O, O, B-JOBDESCRIPTOR, B-JOBTITLE, I-JOBTITLE, I-JOBTITLE, O, B-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, I-COMPANY_NAME, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    tokenised_unmasked_text  \n",
       "0  [mr, ., adolph, ##us, reagan, z, ##ie, ##mann, ,, as, a, central, principal, applications, executive, at, mclaughlin, ,, nad, ##er, and, pu, ##rdy, ,, your, knowledge, of, change, management, is, vital, for, our, company, ', s, transformation, ., we, request, you, to, create, a, change, management, strategy, .]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢視資料集中的第一筆資料\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(immutable_dataset[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個表格結構，包含四個欄位，分別是：\n",
    "\n",
    "* `masked_text`: 這是一個包含 PII 遮掩的文本，我們將使用這個文本來訓練模型，以此為輸出。\n",
    "\n",
    "* `unmasked_text`: 這是一個包含 PII 資訊的原始文本，我們將使用這個文本來訓練模型，以此為輸入。\n",
    "\n",
    "其餘 `token_entity_labels` 及 `tokenised_unmasked_text` 是我們在訓練過程中不會使用到的欄位。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前處理\n",
    "\n",
    "方便演示及訓練，我們將對資料進行以下前處理：\n",
    "\n",
    "1. 保留 `masked_text` 及 `unmasked_text` 欄位。\n",
    "2. 將資料及分為訓練集，驗證集及測試集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['masked_text', 'unmasked_text'],\n",
       "    num_rows: 5397\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保留必要 features: 'masked_text', 'unmasked_text'\n",
    "dataset = immutable_dataset.remove_columns(['token_entity_labels', 'tokenised_unmasked_text'])\n",
    "# 顯示處理後的資料\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['masked_text', 'unmasked_text'],\n",
       "        num_rows: 4312\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['masked_text', 'unmasked_text'],\n",
       "        num_rows: 1079\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['masked_text', 'unmasked_text'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve 0.1% of the training set for testing\n",
    "test_dataset = dataset.train_test_split(\n",
    "  test_size=0.001, # 0.1% of the data is used for testing\n",
    "  shuffle=False, # Ensure that train and validation sets are the same across runs\n",
    "  )\n",
    "# Split into 80% training and 20% validation sets\n",
    "train_dataset = test_dataset['train'].train_test_split(\n",
    "  test_size=0.2, # 20% of the data is used for validation\n",
    "  shuffle=False, # Ensure that train and test sets are the same across runs\n",
    "  )\n",
    "dataset = DatasetDict({\n",
    "  'train': train_dataset['train'],\n",
    "  'validation': train_dataset['test'],\n",
    "  'test': test_dataset['test'],\n",
    "  })\n",
    "# 顯示處理後的資料\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unmasked_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "357c1b7b-4df8-4b5a-8f3c-7730816fda1a",
       "rows": [
        [
         "0",
         "[PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.",
         "Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy."
        ],
        [
         "1",
         "Hello [FIRSTNAME_1], would you please investigate the potential fallouts associated with the revisions in the [JOBAREA_1] department? Please incorporate your findings in your management strategy required previously.",
         "Hello Hannah, would you please investigate the potential fallouts associated with the revisions in the Security department? Please incorporate your findings in your management strategy required previously."
        ],
        [
         "2",
         "We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at [EMAIL_1].",
         "We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at Bartholome_Goldner85@yahoo.com."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>unmasked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.</td>\n",
       "      <td>Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello [FIRSTNAME_1], would you please investigate the potential fallouts associated with the revisions in the [JOBAREA_1] department? Please incorporate your findings in your management strategy required previously.</td>\n",
       "      <td>Hello Hannah, would you please investigate the potential fallouts associated with the revisions in the Security department? Please incorporate your findings in your management strategy required previously.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at [EMAIL_1].</td>\n",
       "      <td>We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at Bartholome_Goldner85@yahoo.com.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            masked_text  \\\n",
       "0  [PREFIX_1] [FIRSTNAME_1] [MIDDLENAME_1] [LASTNAME_1], as a [JOBDESCRIPTOR_1] [JOBTITLE_1] at [COMPANY_NAME_1], your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.   \n",
       "1                               Hello [FIRSTNAME_1], would you please investigate the potential fallouts associated with the revisions in the [JOBAREA_1] department? Please incorporate your findings in your management strategy required previously.   \n",
       "2                                              We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at [EMAIL_1].   \n",
       "\n",
       "                                                                                                                                                                                                                                      unmasked_text  \n",
       "0  Mr. Adolphus Reagan Ziemann, as a Central Principal Applications Executive at McLaughlin, Nader and Purdy, your knowledge of change management is vital for our company's transformation. We request you to create a change management strategy.  \n",
       "1                                     Hello Hannah, would you please investigate the potential fallouts associated with the revisions in the Security department? Please incorporate your findings in your management strategy required previously.  \n",
       "2                     We also request a review of our policies with respect to the upcoming changes and to bring in your expertise in case a policy change is advised. You can communicate the updates via email at Bartholome_Goldner85@yahoo.com.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示前 first_n_data 筆資料\n",
    "first_n_data = 3\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(dataset['train'].select(range(first_n_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批次大小 (Batch Size) 和 梯度累積步數 (Gradient Accumulation Steps)\n",
    "\n",
    "批次大小（batch size）和梯度累積步數（gradient accumulation steps）之間的關係可以簡單地說明如下：\n",
    "\n",
    "* 批次大小（batch size）：每次訓練迭代中使用的樣本數量。較大的批次大小通常需要更多的內存。\n",
    "* 梯度累積步數（gradient accumulation steps）：在更新模型權重之前累積梯度的迭代次數。這允許使用較小的批次大小來模擬較大的批次大小。\n",
    "\n",
    "當內存限制無法直接使用大批次大小時，可以通過梯度累積來實現。例如：\n",
    "\n",
    "* 如果批次大小是 8，梯度累積步數是 4，這相當於使用批次大小為 32（8 * 4）進行訓練。\n",
    "\n",
    "這樣可以在內存有限的情況下實現大批次大小的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 訓練相關設定\n",
    "class Config(BaseModel):\n",
    "  model_name: str = 'google/flan-t5-base' # Fine-tuned Language Network with T5\n",
    "  saved_model_path: str = os.path.join('saved_model', f'{__ipynb_file__}') # path to save the trained model\n",
    "  saved_lora_path: str = os.path.join('saved_model', f'{__ipynb_file__}_lora') # path to save the trained LORA model\n",
    "  batch_size: int = 4 # size of the input batch in training and evaluation\n",
    "  gradient_accumulation_steps: int = 2 # number of updates steps to accumulate before performing a backward/update pass\n",
    "  epochs: int = 2 # number of times to iterate over the entire training dataset\n",
    "  lr: float = 2e-4 # learning rate, controls how fast or slow the model learns\n",
    "  weight_decay: float = 0.01 # weight decay, helps the model stay simple and avoid overfitting by penalizing large weights.\n",
    "  eval_metric: str = 'bleu' # evaluation metric, 'bleu' or 'sacrebleu'\n",
    "\n",
    "  # 文本生成相關設定\n",
    "  temperature: float = 0.1 # temperature for sampling\n",
    "  max_new_tokens: int = 125 # 限制最大生成字數\n",
    "  repetition_penalty: float = 1.5 # 重複機率, 1~2 之間, 1.0 (no penalty), 2.0 (maximum penalty)\n",
    "\n",
    "  # LORA 相關設定\n",
    "  rank: int = 128 # rank of the Lora layers\n",
    "  lora_alpha: int = rank * 2 # alpha for Lora scaling.\n",
    "  lora_dropout: float = 0.05 # dropout probability for Lora layers\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning 前的表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入預訓練分詞器 (Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='google/flan-t5-base', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 透過預訓練模型取得 Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.model_name,\n",
    ")\n",
    "pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<pad>'\n"
     ]
    }
   ],
   "source": [
    "# 檢視 Tokenizer，是否存在 padding token 及 padding side 等資訊\n",
    "pprint(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'right'\n"
     ]
    }
   ],
   "source": [
    "pprint(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果沒有定義 `pad_token`，請定義一個 `pad_token`，並將其加入 Tokenizer 中。\n",
    "* 如果 `padding_side` 不是 `right`，請將其設定為 `right`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Add pad_token to the tokenizer\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n",
    "  print('=== 設定 Padding Token ===')\n",
    "  pprint(tokenizer)\n",
    "# Make sure padding_side is 'right'\n",
    "if tokenizer.padding_side != 'right':\n",
    "  tokenizer.padding_side = 'right'\n",
    "  print('=== 設定 Padding Side ===')\n",
    "  pprint(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入預訓練模型\n",
    "\n",
    "透過 `T5ForConditionalGeneration` 用於摘要，翻譯等序列映射到序列 (Sequence to Sequence, Seq2Seq) 任務的類別，它可以載入預訓練的 Flan T5 模型進行文本生成任務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "  config.model_name,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這是一個典型的 Encoder-Decoder 模型。\n",
    "\n",
    "```json\n",
    "T5ForConditionalGeneration(\n",
    "  (shared): Embedding(32128, 512)\n",
    "  (encoder): T5Stack(\n",
    "    (embed_tokens): Embedding(32128, 512)\n",
    "    ...\n",
    "  )\n",
    "  (decoder): T5Stack(\n",
    "    (embed_tokens): Embedding(32128, 512)\n",
    "    ...\n",
    "  )\n",
    "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
    ")    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詠唱格式化 (Prompt Formatting)\n",
    "\n",
    "定義詠唱 (Prompt) 格式，我們將創建一個格式化函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "system_message = 'Mask the personal identifiable information:'\n",
    "\n",
    "def instruction_formatter(x, tokenize: bool = False):\n",
    "  input = f\"{system_message} {x['unmasked_text']}\"\n",
    "  if tokenize:\n",
    "    return tokenizer(\n",
    "      [input],\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "    ).to(device)\n",
    "  else:\n",
    "    return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mask the personal identifiable information: We need a comprehensive review '\n",
      " 'of privacy laws and regulations regarding the handling and sharing of masked '\n",
      " 'credit card numbers, such as 1160254613057002.')\n"
     ]
    }
   ],
   "source": [
    "# tokenize=False 代表不進行 Tokenize，直接回傳原始文字\n",
    "input = instruction_formatter(dataset['test'][0], tokenize=False)\n",
    "pprint(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0'),\n",
      " 'input_ids': tensor([[23709,     8,   525, 22185,   251,    10,   101,   174,     3,     9,\n",
      "          3452,  1132,    13,  4570,  3786,    11,  4750,  1918,     8,  5834,\n",
      "            11,  2178,    13,     3,    51, 23552,   998,   895,  2302,     6,\n",
      "           224,    38,   850,  3328,  1828,  4448, 21448, 28363, 12328,     1]],\n",
      "       device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "# tokenize=True 代表進行 Tokenize，回傳 Tokenize 後的 ID 及 attention mask tensors\n",
    "tokenized_input = instruction_formatter(dataset['test'][0], tokenize=True)\n",
    "pprint(tokenized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer 回傳內容包含兩個主要部分：`input_ids` 和 `attention_mask`。以下是詳細解釋：\n",
    "\n",
    "* `input_ids`: 是一個張量 (tensor)，包含了輸入文本的 token IDs。這些 IDs 是由 tokenizer 將文本轉換為數字表示後得到的。\n",
    "\n",
    "* `attention_mask`: 同樣是一個張量，用於指示模型應該關注哪些位置。值為 1 的位置表示應該關注，值為 0 的位置表示應該忽略。在這個例子中，`attention_mask` 的值全為 1，表示模型應該關注所有位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23709 -> Mask\n",
      "8 -> the\n",
      "525 -> personal\n",
      "22185 -> identifiable\n",
      "251 -> information\n",
      "10 -> :\n",
      "101 -> We\n",
      "174 -> need\n",
      "3 -> \n",
      "9 -> a\n",
      "3452 -> comprehensive\n",
      "1132 -> review\n",
      "13 -> of\n",
      "4570 -> privacy\n",
      "3786 -> laws\n",
      "11 -> and\n",
      "4750 -> regulations\n",
      "1918 -> regarding\n",
      "8 -> the\n",
      "5834 -> handling\n",
      "11 -> and\n",
      "2178 -> sharing\n",
      "13 -> of\n",
      "3 -> \n",
      "51 -> m\n",
      "23552 -> asked\n",
      "998 -> credit\n",
      "895 -> card\n",
      "2302 -> numbers\n",
      "6 -> ,\n",
      "224 -> such\n",
      "38 -> as\n",
      "850 -> 11\n",
      "3328 -> 60\n",
      "1828 -> 25\n",
      "4448 -> 46\n",
      "21448 -> 130\n",
      "28363 -> 570\n",
      "12328 -> 02.\n",
      "1 -> </s>\n"
     ]
    }
   ],
   "source": [
    "# 透過 Tokenizer 的 decode 方法將 ID 轉換回文字，並列顯示出來\n",
    "for id in tokenized_input['input_ids'][0]:\n",
    "  print(f'{id} -> {tokenizer.decode([id])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "經過 Tokenizer 處理後再還原回文本，我們可以看到 Tokenizer 處理後的文本最後多了一個 `</s>` token，這是因為 T5 模型的輸入文本需要以 `</s>` 結尾。`</s>` token 用於指示模型輸入的結束，即 `eos_token`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 前的表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 單筆演示生成回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "# 透過預訓練模型生成回應\n",
    "output_ids = model.generate(\n",
    "  **tokenized_input,\n",
    "  temperature=config.temperature,\n",
    "  max_new_tokens=config.max_new_tokens,\n",
    "  repetition_penalty=config.repetition_penalty,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     3,    51, 23552,   998,   895,  2302,     1]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 output_ids 轉換為文字\n",
    "output = tokenizer.decode(\n",
    "  output_ids[0],\n",
    "  skip_special_tokens=False, # 決定是否跳過特殊 token（例如，開始和結束標記）。\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<pad> masked credit card numbers</s>'\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 批次處理模型表現\n",
    "\n",
    "初步了解如何生成模型的回應，我們將定義一個 `generate()` 函數來生成模型的回應。這個函數接受一個輸入文本，並生成模型的回應。藉由這個函數，我們可以批次處理資料。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將以上程式碼整理成一個函式，方便我們批次處理資料\n",
    "def generator(x, model):\n",
    "  tokenized_input = instruction_formatter(x, tokenize=True)\n",
    "  output_ids = model.generate(\n",
    "    **tokenized_input,\n",
    "    temperature=config.temperature,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    repetition_penalty=config.repetition_penalty,\n",
    "  )\n",
    "  return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.Config'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.Config'>: __main__.Config has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.54s/ examples]\n"
     ]
    }
   ],
   "source": [
    "# 這個步驟可能會花費一些時間，所以我們只處理前 first_n_data 筆資料\n",
    "first_n_dataset = dataset['test'].select(range(first_n_data))\n",
    "\n",
    "# 透過預訓練模型生成回應，將其新增到 first_n_dataset 的 pt_response 欄位中\n",
    "first_n_dataset = first_n_dataset.map(\n",
    "  lambda x: {\n",
    "    **x,\n",
    "    \"pt_response\": generator(x, model),\n",
    "  },\n",
    "  batched=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unmasked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pt_response",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "eaead8fa-2128-4bbb-8d50-e87a2cfe1ff8",
       "rows": [
        [
         "0",
         "We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].",
         "We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.",
         "masked credit card numbers"
        ],
        [
         "1",
         "Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].",
         "Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.",
         "MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09."
        ],
        [
         "2",
         "Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?",
         "Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?",
         "no"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>unmasked_text</th>\n",
       "      <th>pt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].</td>\n",
       "      <td>We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.</td>\n",
       "      <td>masked credit card numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].</td>\n",
       "      <td>Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.</td>\n",
       "      <td>MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?</td>\n",
       "      <td>Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  masked_text  \\\n",
       "0  We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].   \n",
       "1                                 Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].   \n",
       "2                                                         Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?   \n",
       "\n",
       "                                                                                                                                                                   unmasked_text  \\\n",
       "0                     We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.   \n",
       "1                                             Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.   \n",
       "2  Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?   \n",
       "\n",
       "                                                                                                                                       pt_response  \n",
       "0                                                                                                                       masked credit card numbers  \n",
       "1  MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.  \n",
       "2                                                                                                                                               no  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示預訓練模型預測結果\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(first_n_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA 的訓練策略\n",
    "\n",
    "LoRA（Low-Rank Adaptation）是一種用於訓練大型語言模型的技術，旨在提高訓練效率並減少計算資源的需求。以下是為何需要透過LoRA訓練的一些原因：\n",
    "\n",
    "* 降低計算成本：LoRA 通過將模型的權重矩陣分解為低秩矩陣，顯著減少了參數的數量，從而降低了計算成本和內存需求。\n",
    "\n",
    "* 加速訓練速度：由於參數數量減少，LoRA 可以加速模型的訓練過程，使得在相同的硬件資源下能夠更快地完成訓練。\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 247,577,856, Trainable Parameters: 247,577,856\n"
     ]
    }
   ],
   "source": [
    "# 查看預訓練模型可訓練的參數量，其數量相當龐大，所以需要透過 Low Rank Adaptation (LoRA) 來降低參數量\n",
    "print('Parameters: {:,}, Trainable Parameters: {:,}'.format(\n",
    "  model.num_parameters(),\n",
    "  model.num_parameters(only_trainable=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA 配置\n",
    "\n",
    "* `task_type`: TaskType.SEQ_2_SEQ_LM 指定任務類型為序列到序列的語言模型 (Sequence-to-Sequence Language Model)。\n",
    "\n",
    "* `rank`: 是低秩矩陣的秩(rank)，它決定了 LoRA 層的參數數量。較低的 `r` 值意味著較少的參數，從而減少了模型的計算和存儲需求。具體來說，LoRA 通過將全連接層的權重矩陣分解為兩個低秩矩陣來實現參數高效化。`r` 值越小，這兩個低秩矩陣的維度越小，這個練習我們採用 128。\n",
    "\n",
    "* `lora_alpha`: 是一個縮放因子，用於調整 LoRA 層的輸出。它控制了低秩矩陣的影響力。較高的 `lora_alpha` 值會增加 LoRA 層的影響力，也就是說值越高，越容易把大模型既有的能力給覆蓋掉。具體來說，LoRA 層的輸出會乘以這個縮放因子，這個練習我們採用常見的比例為 `rank` 的兩倍。\n",
    "\n",
    "* `lora_dropout`: 是一個丟棄率，用於在訓練過程中隨機丟棄 LoRA 層的一部分輸出。這有助於防止過擬合，並提高模型的泛化能力。例如，`lora_dropout` 設置為 0.1 表示在每次前向傳播中，有 10% 的 LoRA 層輸出會被隨機設置為零。\n",
    "\n",
    "* `target_module`: 指定了應用 LoRA 的目標模塊。這通常是模型中的某些特定層或子模塊，例如 Transformer 模型中的注意力層，可以透過 `model.named_parameters` 查看。通過指定 `target_module`，你可以靈活地選擇在哪些層應用 LoRA，以便在保持模型性能的同時減少參數數量。\n",
    "\n",
    "> 廣為周知的模型當未指定 `target_module`，透過 `get_peft_model` 加載 Lora 適配模型時，會自動設定。\n",
    "> 可以先嘗試不指定，若出現錯誤再試著設定注意力相關的參數層。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.SEQ_2_SEQ_LM: 'SEQ_2_SEQ_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path=None,\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules=None,\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "# LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "  task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "  r=config.rank,\n",
    "  lora_alpha=config.lora_alpha,\n",
    "  lora_dropout=config.lora_dropout,\n",
    "  # target_modules=['v', 'q'], # 有別於 Phi3ForCausalLM 需要指定 target_modules, 這次 LoRA 可以自動判斷\n",
    ")\n",
    "\n",
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加載 LoRA 適配模型\n",
    "\n",
    "搭配預訓模型及 LoRA 配置，我們可以加載 LoRA 適配模型。我們可以觀察受到降維影響的模型層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 加載 LoRA 適配模型\n",
    "peft_model = get_peft_model(\n",
    "  model, # 預訓練模型\n",
    "  lora_config, # LoRA 配置\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type=<TaskType.SEQ_2_SEQ_LM: 'SEQ_2_SEQ_LM'>,\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path='google/flan-t5-base',\n",
      "           revision=None,\n",
      "           inference_mode=False,\n",
      "           r=128,\n",
      "           target_modules={'v', 'q'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=256,\n",
      "           lora_dropout=0.05,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA 適配模型\n",
    "\n",
    "加載 LoRA 適配模型後, 觀察受 LoRA 影響的模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): T5ForConditionalGeneration(\n",
       "      (shared): Embedding(32128, 768)\n",
       "      (encoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然這次我們沒有特別指定 `target_module`，但是在這個例子中，我們使用的是 Flan T5 模型，因此預設 Ｑ 及 Ｖ 注意力層受到 LoRA 的影響。\n",
    "\n",
    "```json\n",
    "                (SelfAttention): T5Attention(\n",
    "                  (q): lora.Linear(\n",
    "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
    "                    (lora_dropout): ModuleDict(\n",
    "                      (default): Dropout(p=0.05, inplace=False)\n",
    "                    )\n",
    "                    (lora_A): ModuleDict(\n",
    "                      (default): Linear(in_features=512, out_features=128, bias=False)\n",
    "                    )\n",
    "                    (lora_B): ModuleDict(\n",
    "                      (default): Linear(in_features=128, out_features=384, bias=False)\n",
    "                    )\n",
    "                    (lora_embedding_A): ParameterDict()\n",
    "                    (lora_embedding_B): ParameterDict()\n",
    "                    (lora_magnitude_vector): ModuleDict()\n",
    "                  )\n",
    "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
    "                  (v): lora.Linear(\n",
    "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
    "                    (lora_dropout): ModuleDict(\n",
    "                      (default): Dropout(p=0.05, inplace=False)\n",
    "                    )\n",
    "                    (lora_A): ModuleDict(\n",
    "                      (default): Linear(in_features=512, out_features=128, bias=False)\n",
    "                    )\n",
    "                    (lora_B): ModuleDict(\n",
    "                      (default): Linear(in_features=128, out_features=384, bias=False)\n",
    "                    )\n",
    "                    (lora_embedding_A): ParameterDict()\n",
    "                    (lora_embedding_B): ParameterDict()\n",
    "                    (lora_magnitude_vector): ModuleDict()\n",
    "                  )\n",
    "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
    "                  (relative_attention_bias): Embedding(32, 6)\n",
    "                )\n",
    "```              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練參數量也從原先 247M 大大減少為 14M。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,155,776 || all params: 261,733,632 || trainable%: 5.4085\n"
     ]
    }
   ],
   "source": [
    "# 查看可訓練的參數量\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理\n",
    "\n",
    "在訓練模型之前，我們需要對資料進行預處理。這包括將文本轉換為模型可以理解的格式，包含輸入及輸出標籤 (Label)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定義預處理函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "  inputs = [ f'{system_message} {q}' for q in dataset['unmasked_text'] ]\n",
    "  tokenized_inputs = tokenizer(\n",
    "    inputs,\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='pt',\n",
    "  )\n",
    "  # Temporarily sets the tokenizer for encoding the targets.\n",
    "  # Useful for tokenizer associated to sequence-to-sequence models that need different processing for the labels.\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    input_labels = tokenizer(\n",
    "      dataset['masked_text'],\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "  # Replace all EOS tokens with -100 after eos_token_id for the labels\n",
    "  input_labels['input_ids'] = input_labels['input_ids'].masked_fill(\n",
    "    input_labels['input_ids'] == tokenizer.eos_token_id,\n",
    "    -100,\n",
    "  )\n",
    "  tokenized_inputs['labels'] = input_labels['input_ids']\n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[23709,     8,   525, 22185,   251,    10,   101,   174,     3,     9,\n",
      "          3452,  1132,    13,  4570,  3786,    11,  4750,  1918,     8,  5834,\n",
      "            11,  2178,    13,     3,    51, 23552,   998,   895,  2302,     6,\n",
      "           224,    38,   850,  3328,  1828,  4448, 21448, 28363, 12328,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [23709,     8,   525, 22185,   251,    10,   421,  1188,  6560, 17137,\n",
      "            15,   537,    65,     3,     9, 11417,    81,  4570,  3786,  1918,\n",
      "             8,   169,    11,  1606,    13,    70,  1407,    31,     7,     3,\n",
      "         16605,  1115,     3,  4327,    10,    89,   632,    10,    15,    15,\n",
      "            10,  1206,    10,    15,   519,    10, 12900,     1,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [23709,     8,   525, 22185,   251,    10,    27,     7,    34,  1281,\n",
      "            12,  1078,  1139,  3102,   251,     6,   224,    38, 30699,    87,\n",
      "         20734,    41, 17772,    77,   235,     7,   107,   117,   412,   117,\n",
      "          5869,  2143,  6328,     3,     4,     3, 22567, 18189,   117,     3,\n",
      "            52,   208,    10,  8797, 13520,   350,  5007,    32, 20173,  2915,\n",
      "         19621, 19570,    87,  8797, 27376,    16,  4408,   663,    28,  4570,\n",
      "          3786,    58,     1]]),\n",
      " 'labels': tensor([[  101,   174,     3,     9,  3452,  1132,    13,  4570,  3786,    11,\n",
      "          4750,  1918,     8,  5834,    11,  2178,    13,     3,    51, 23552,\n",
      "           998,   895,  2302,     6,   224,    38,   784, 23010,  9914, 12145,\n",
      "          6122, 12920,   834,   536,  4275,  -100],\n",
      "        [  421,  1188,   784, 20245, 11053, 17683,   834,   536,   908,    65,\n",
      "             3,     9, 11417,    81,  4570,  3786,  1918,     8,   169,    11,\n",
      "          1606,    13,    70,  1407,    31,     7,     3, 16605,  1115,   784,\n",
      "         16605,   834,   536,  4275,  -100,     0],\n",
      "        [   27,     7,    34,  1281,    12,  1078,  1139,  3102,   251,     6,\n",
      "           224,    38,   784, 11927,  4763,   517,  6431,   834,   536,   908,\n",
      "            16,  4408,   663,    28,  4570,  3786,    58,  -100,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pprint(preprocess_function(dataset['test'][:first_n_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "經過預處理後， 輸入文本將被轉換為模型可以理解的格式，包含 `input_ids` 和 `attention_mask`；輸出文本將被轉換為 `labels`，且 EOS token 會被置換為 -100，以確保填充標記被損失函數忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 批次處理資料\n",
    "\n",
    "使用 `Dataset.map()` 方法，選項設置為 `batched=True`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4312/4312 [00:00<00:00, 8577.39 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1079/1079 [00:00<00:00, 10109.62 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1806.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "  preprocess_function,\n",
    "  batched=True, # 是否以批次進行處理\n",
    "  remove_columns=dataset['train'].column_names, # 移除不必要的欄位\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料校對器 (Data Collator)\n",
    "\n",
    "在微調語言模型時，使用 data collator 是為了有效地準備和處理批次數據。以下是使用 data collator 的幾個主要原因：\n",
    "\n",
    "* 動態填充 (Dynamic Padding): 不同長度的序列需要填充到相同的長度，以便能夠在同一批次中進行處理。Data collator 可以自動計算每個批次的最大長度，並對序列進行適當的填充。\n",
    "\n",
    "* 批次處理 (Batch Processing): Data collator 可以將多個樣本組合成一個批次，這樣可以更高效地利用計算資源，特別是在使用 GPU 或 TPU 時。\n",
    "\n",
    "* 生成注意力掩碼 (Attention Masks): 在填充序列時，data collator 會生成相應的注意力掩碼 (attention masks)，以確保模型只關注實際的數據部分，而忽略填充部分。\n",
    "\n",
    "* 簡化代碼 (Code Simplification): 使用 data collator 可以簡化數據處理的代碼，減少手動處理數據的繁瑣步驟，讓開發者專注於模型設計和訓練。\n",
    "\n",
    "總之，data collator 在微調語言模型時提供了便利和效率，確保數據能夠以一致且高效的方式進行處理。\n",
    "\n",
    "在這邊我們使用 `DataCollatorForSeq2Seq` 是一個專門用於 BART 或 T5 這類 Seq2Seq 模型的數據整理器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 設定 DataCollatorForCompletionOnlyLM\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  tokenizer=tokenizer,\n",
    "  model=peft_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0]]]),\n",
      " 'decoder_input_ids': tensor([[[    0,   101,   174,     3,     9,  3452,  1132,    13,  4570,  3786,\n",
      "             11,  4750,  1918,     8,  5834,    11,  2178,    13,     3,    51,\n",
      "          23552,   998,   895,  2302,     6,   224,    38,   784, 23010,  9914,\n",
      "          12145,  6122, 12920,   834,   536,  4275,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0],\n",
      "         [    0,   421,  1188,   784, 20245, 11053, 17683,   834,   536,   908,\n",
      "             65,     3,     9, 11417,    81,  4570,  3786,  1918,     8,   169,\n",
      "             11,  1606,    13,    70,  1407,    31,     7,     3, 16605,  1115,\n",
      "            784, 16605,   834,   536,  4275,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0],\n",
      "         [    0,    27,     7,    34,  1281,    12,  1078,  1139,  3102,   251,\n",
      "              6,   224,    38,   784, 11927,  4763,   517,  6431,   834,   536,\n",
      "            908,    16,  4408,   663,    28,  4570,  3786,    58,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]]),\n",
      " 'input_ids': tensor([[[23709,     8,   525, 22185,   251,    10,   101,   174,     3,     9,\n",
      "           3452,  1132,    13,  4570,  3786,    11,  4750,  1918,     8,  5834,\n",
      "             11,  2178,    13,     3,    51, 23552,   998,   895,  2302,     6,\n",
      "            224,    38,   850,  3328,  1828,  4448, 21448, 28363, 12328,     1,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0],\n",
      "         [23709,     8,   525, 22185,   251,    10,   421,  1188,  6560, 17137,\n",
      "             15,   537,    65,     3,     9, 11417,    81,  4570,  3786,  1918,\n",
      "              8,   169,    11,  1606,    13,    70,  1407,    31,     7,     3,\n",
      "          16605,  1115,     3,  4327,    10,    89,   632,    10,    15,    15,\n",
      "             10,  1206,    10,    15,   519,    10, 12900,     1,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0],\n",
      "         [23709,     8,   525, 22185,   251,    10,    27,     7,    34,  1281,\n",
      "             12,  1078,  1139,  3102,   251,     6,   224,    38, 30699,    87,\n",
      "          20734,    41, 17772,    77,   235,     7,   107,   117,   412,   117,\n",
      "           5869,  2143,  6328,     3,     4,     3, 22567, 18189,   117,     3,\n",
      "             52,   208,    10,  8797, 13520,   350,  5007,    32, 20173,  2915,\n",
      "          19621, 19570,    87,  8797, 27376,    16,  4408,   663,    28,  4570,\n",
      "           3786,    58,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0]]]),\n",
      " 'labels': tensor([[[  101,   174,     3,     9,  3452,  1132,    13,  4570,  3786,    11,\n",
      "           4750,  1918,     8,  5834,    11,  2178,    13,     3,    51, 23552,\n",
      "            998,   895,  2302,     6,   224,    38,   784, 23010,  9914, 12145,\n",
      "           6122, 12920,   834,   536,  4275,  -100,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0],\n",
      "         [  421,  1188,   784, 20245, 11053, 17683,   834,   536,   908,    65,\n",
      "              3,     9, 11417,    81,  4570,  3786,  1918,     8,   169,    11,\n",
      "           1606,    13,    70,  1407,    31,     7,     3, 16605,  1115,   784,\n",
      "          16605,   834,   536,  4275,  -100,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0],\n",
      "         [   27,     7,    34,  1281,    12,  1078,  1139,  3102,   251,     6,\n",
      "            224,    38,   784, 11927,  4763,   517,  6431,   834,   536,   908,\n",
      "             16,  4408,   663,    28,  4570,  3786,    58,  -100,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n"
     ]
    }
   ],
   "source": [
    "# 展示 DataCollatorForSeq2Seq 的輸出\n",
    "features = [tokenized_dataset[\"test\"][:first_n_data]]\n",
    "batch = data_collator(features)\n",
    "pprint(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡要注意的主要是第一個例子與第二個例子長度不一，所以長度不足的例子的 `input_ids` 和 `attention_mask` 已經在右側填充了一個 [PAD] 標記（其 ID 是 0）。 類似地，我們可以看到 `labels` 已用 -100 填充，以確保填充標記被損失函數忽略。最後，我們可以看到一個新的 `decoder_input_ids`，它通過在第一個條目中插入 [PAD] 標記將標籤向右移動。\n",
    "\n",
    "我們終於擁有了訓練所需的所有的前期準備！我們現在只需要使用標準參數實例化訓練器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型評估函數\n",
    "\n",
    "在訓練過程中包含度量標準通常有助於評估模型的性能。您可以使用 Evaluate 庫快速加載評估方法。\n",
    "\n",
    "BLEU 和 ROUGE 分數都是在機器翻譯任務中廣泛使用的重要評估指標，但它們側重的方面不同，BLEU 側重於精確度，而 ROUGE 側重於召回率。\n",
    "\n",
    "* `BLEU (Bilingual Evaluation Understudy)`: BLEU 分數側重於精確度。主要目標是自動將文本從一種語言翻譯成另一種語言。BLEU 分數量化機器翻譯的文本與參考翻譯之間的相似性，這種測量是使用 n-gram 進行的。\n",
    "\n",
    "* `SacreBLEU`: SacreBLEU 通過標準化和簡化使用過程，提供了一個更一致和方便的評分方法。SacreBLEU 的標準化計算方法確保了不同實驗和研究之間的分數具有可比性，並且自動處理常見的文本預處理步驟，使其更易於使用。\n",
    "\n",
    "* `ROUGE (Recall-Oriented Understudy for Gisting Evaluation)`: ROUGE 分數側重於召回率。它將自動生成的摘要或翻譯與一個或多個參考進行比較。ROUGE 分數範圍從 0 到 1，反映了機器生成的摘要與參考之間的相似性，分數越高表示相似性越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(config.eval_metric)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack predictions and labels from the input\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Apply the tokenizer to decode the predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels to the tokenizer pad_token_id\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Apply the tokenizer to decode the labels\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute evaluation metrics for bleu\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "    )\n",
    "    if 'bleu' in result: # for bleu\n",
    "        return {\"bleu\": result[\"bleu\"]}\n",
    "    elif 'score' in result: # for sacrebleu\n",
    "        return {\"bleu\": result[\"score\"]}\n",
    "    else:\n",
    "        raise ValueError('The evaluation metric is not supported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練參數設定\n",
    "\n",
    "用於設定訓練過程中的各種參數，如學習率、批次大小、梯度累積步數、訓練 epoch 數、權重衰減等。\n",
    "\n",
    "* `output_dir` 指定了訓練輸出的目錄。\n",
    "* `logging_steps` 訓練時的日誌步數，決定每隔多少步輸出一次訓練日誌。\n",
    "* `eval_strategy` 和 `save_strategy` 設定為 'steps'，表示每 `logging_steps` 個 steps 都會進行評估和儲存。\n",
    "* `load_best_model_at_end` 設定為 `True`，表示訓練結束後會載入最佳模型。\n",
    "* `report_to` 設定為 'none'，禁用了 wandb 報告。\n",
    "* `predict_with_generate` 設定為 `True`，表示在評估過程中使用生成的文本進行預測。\n",
    "* `save_total_limit` 設定了最多儲存 5 個 checkpoints。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir=os.path.join('saved_model', f'{__ipynb_file__}_train_log'), # 訓練輸出目錄\n",
    "  learning_rate=config.lr, # 學習率\n",
    "  per_device_train_batch_size=config.batch_size, # 每個設備的訓練批次大小\n",
    "  per_device_eval_batch_size=config.batch_size, # 每個設備的評估批次大小\n",
    "  gradient_accumulation_steps=config.gradient_accumulation_steps, # 梯度累積步數\n",
    "  logging_steps=100, # 訓練時的日誌步數, 預設每 500 步輸出一次日誌\n",
    "  num_train_epochs=config.epochs, # 訓練的總 epoch 數\n",
    "  weight_decay=config.weight_decay, # 權重衰減\n",
    "  eval_strategy='steps', # 評估策略\n",
    "  save_strategy='steps', # 儲存策略\n",
    "  load_best_model_at_end=True, # 訓練完後載入最佳模型\n",
    "  report_to='none', # 禁用 wandb 報告 (Colab 環境預設需要 wandb)\n",
    "  predict_with_generate=True, # 對評估數據集生成文字，針對生成文字計算指標\n",
    "  save_total_limit=5, # 最多儲存 5 個 checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練器初始化\n",
    "\n",
    "用於初始化訓練器，並開始訓練模型。\n",
    "\n",
    "* `model` 是要訓練的模型。\n",
    "* `tokenizer` 是用於處理文本的分詞器。\n",
    "* `train_dataset` 和 `eval_dataset` 是訓練和評估數據集。\n",
    "* `data_collator` 是用於整理數據的數據整理器。\n",
    "* `compute_metrics` 是用於計算度量標準的函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/hkxkfjqd58j9t_718vfr4tjw0000gn/T/ipykernel_2487/4166051500.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=peft_model, # 要訓練的模型\n",
    "    tokenizer=tokenizer, # 使用的分詞器\n",
    "    args=training_args, # 訓練參數\n",
    "    train_dataset=tokenized_dataset['train'], # 訓練數據集\n",
    "    eval_dataset=tokenized_dataset['validation'], # 評估數據集\n",
    "    data_collator=data_collator, # 數據整理器\n",
    "    compute_metrics=compute_metrics, # 模型評估函數\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1078' max='1078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1078/1078 54:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.291600</td>\n",
       "      <td>0.283348</td>\n",
       "      <td>0.241450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.119987</td>\n",
       "      <td>0.241154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.074505</td>\n",
       "      <td>0.234354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.234213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.235815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.044429</td>\n",
       "      <td>0.236459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.237017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>0.235019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.239071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.035304</td>\n",
       "      <td>0.236368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1078, training_loss=0.6050178195196092, metrics={'train_runtime': 3267.3594, 'train_samples_per_second': 2.639, 'train_steps_per_second': 0.33, 'total_flos': 2399136932966400.0, 'train_loss': 0.6050178195196092, 'epoch': 2.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 開始訓練，這可能需要一些時間\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練完成後，您可以通過運行 `Trainer.evaluate()` 方法在驗證集上評估模型的性能。它會計算模型的損失和其他評估指標，並返回這些結果。這對於了解模型在未見數據上的表現非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:325: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03530417010188103,\n",
       " 'eval_bleu': 0.23636758649616496,\n",
       " 'eval_runtime': 204.9096,\n",
       " 'eval_samples_per_second': 5.266,\n",
       " 'eval_steps_per_second': 1.318,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 LoRA 模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# 保存 Lora 参数\n",
    "peft_model.save_pretrained(\n",
    "  config.saved_lora_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_model/pii-masking-encode-decode-dfca0739-dd45-403e-912e-dc82b3708a3f/tokenizer_config.json',\n",
       " 'saved_model/pii-masking-encode-decode-dfca0739-dd45-403e-912e-dc82b3708a3f/special_tokens_map.json',\n",
       " 'saved_model/pii-masking-encode-decode-dfca0739-dd45-403e-912e-dc82b3708a3f/spiece.model',\n",
       " 'saved_model/pii-masking-encode-decode-dfca0739-dd45-403e-912e-dc82b3708a3f/added_tokens.json',\n",
       " 'saved_model/pii-masking-encode-decode-dfca0739-dd45-403e-912e-dc82b3708a3f/tokenizer.json')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存 Tokenizer\n",
    "tokenizer.save_pretrained(config.saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 釋放資源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import garbage collector\n",
    "import gc\n",
    "\n",
    "# 釋放 GPU 記憶體\n",
    "del trainer\n",
    "del tokenizer\n",
    "\n",
    "peft_model.to('cpu')\n",
    "del peft_model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估微調模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入微調分詞器 (Tokenizer)\n",
    "\n",
    "從已經完成訓練的模型取得 Tokenizer，可以留意這個訓練時保存下來的 Tokenizer 仍保有訓練時的設定，包涵 `pad_token` 和 `padding_side`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  config.saved_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<pad>'\n"
     ]
    }
   ],
   "source": [
    "# 檢視 Tokenizer 是否存在 padding token 及 padding side 等資訊\n",
    "pprint(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'right'\n"
     ]
    }
   ],
   "source": [
    "pprint(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入微調後模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ft_model = PeftModel.from_pretrained(\n",
    "  model, # 預訓練模型\n",
    "  config.saved_lora_path, # LoRA 適配模型\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 後的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '__main__.Config'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '__main__.Config'>: __main__.Config has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map:   0%|                                                                                                                                                     | 0/3 [00:00<?, ? examples/s]/Users/jonas/.pyenv/versions/learning-transformer-with-huggingface-3.11.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.06s/ examples]\n"
     ]
    }
   ],
   "source": [
    "# 透過微調模型生成回應，將其新增到 first_n_dataset 的 ft_response 欄位中\n",
    "first_n_dataset = first_n_dataset.map(\n",
    "  lambda x: {\n",
    "    **x,\n",
    "    \"ft_response\": generator(x, ft_model),\n",
    "  },\n",
    "  batched=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unmasked_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pt_response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ft_response",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0086d553-4cd0-49f0-8610-4148bd3dac4a",
       "rows": [
        [
         "0",
         "We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].",
         "We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.",
         "masked credit card numbers",
         "We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDNUMBER_1]. We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDISSUER_1]."
        ],
        [
         "1",
         "Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].",
         "Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.",
         "MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.",
         "Our client [MIDDLENAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1]. Our client [JOBTITLE_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1]."
        ],
        [
         "2",
         "Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?",
         "Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?",
         "no",
         "Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>unmasked_text</th>\n",
       "      <th>pt_response</th>\n",
       "      <th>ft_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].</td>\n",
       "      <td>We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.</td>\n",
       "      <td>masked credit card numbers</td>\n",
       "      <td>We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDNUMBER_1]. We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDISSUER_1].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].</td>\n",
       "      <td>Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.</td>\n",
       "      <td>MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.</td>\n",
       "      <td>Our client [MIDDLENAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1]. Our client [JOBTITLE_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?</td>\n",
       "      <td>Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?</td>\n",
       "      <td>no</td>\n",
       "      <td>Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  masked_text  \\\n",
       "0  We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [MASKEDNUMBER_1].   \n",
       "1                                 Our client [LASTNAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].   \n",
       "2                                                         Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?   \n",
       "\n",
       "                                                                                                                                                                   unmasked_text  \\\n",
       "0                     We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as 1160254613057002.   \n",
       "1                                             Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.   \n",
       "2  Is it legal to store user agent information, such as Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.10.2; rv:9.8) Gecko/20100101 Firefox/9.8.0 in accordance with privacy laws?   \n",
       "\n",
       "                                                                                                                                       pt_response  \\\n",
       "0                                                                                                                       masked credit card numbers   \n",
       "1  MAC address: Our client VonRueden has a query about privacy laws regarding the use and storage of their device's MAC address 97:f0:ee:00:e3:09.   \n",
       "2                                                                                                                                               no   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     ft_response  \n",
       "0  We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDNUMBER_1]. We need a comprehensive review of privacy laws and regulations regarding the handling and sharing of masked credit card numbers, such as [CREDITCARDISSUER_1].  \n",
       "1                                                                      Our client [MIDDLENAME_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1]. Our client [JOBTITLE_1] has a query about privacy laws regarding the use and storage of their device's MAC address [MAC_1].  \n",
       "2                                                                                                                                                                                                                            Is it legal to store user agent information, such as [USERAGENT_1] in accordance with privacy laws?  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示微調模型預測結果\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(first_n_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Download files from Colab workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# ![[ ! -z \"${COLAB_GPU}\" ]] && tar cvzf saved_encoder_model.tgz sample_data/saved_encoder_model/\n",
    "# ![[ ! -z \"${COLAB_GPU}\" ]] && tar cvzf saved_lora_model.tgz sample_data/saved_lora_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if 'COLAB_GPU' in os.environ:\n",
    "#   from google.colab import files\n",
    "#   files.download('saved_encoder_model.tgz')\n",
    "#   files.download('saved_lora_model.tgz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
